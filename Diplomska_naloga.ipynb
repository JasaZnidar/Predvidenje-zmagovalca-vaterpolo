{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasaZnidar/Predvidenje-zmagovalca-vaterpolo/blob/main/Diplomska_naloga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVXdEg3IE6jY"
      },
      "source": [
        "# Setup enviroment and imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBFEUPjNChfb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qckgRTSCkiJ",
        "outputId": "60a0a7db-2512-4066-f6a7-b35886406639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch==2.4.0\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q pyg_lib -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch_geometric -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch_scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch_sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch_cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch_spline_conv -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torcheval\n",
        "!pip install -q scikit-plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_bTeA4IClUF"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pQMPL8B7EWKB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "from torch_geometric import nn, sampler\n",
        "from torch_geometric.data import HeteroData, Data\n",
        "from torch_geometric import transforms as T\n",
        "from torch_geometric import loader\n",
        "from torcheval import metrics as M\n",
        "from torcheval.metrics import R2Score, MeanSquaredError\n",
        "import tqdm\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "from typing import Callable\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCsW9wIPMGhm"
      },
      "source": [
        "## Other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ongtkmPAMJQs"
      },
      "outputs": [],
      "source": [
        "data_file = \"test\"\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "metapath = [\n",
        "    ('team_in_match', 'played_rev', 'player_in_match'),\n",
        "    ('player_in_match', 'player_instance_rev', 'player'),\n",
        "    ('player', 'player_instance', 'player_in_match'),\n",
        "    ('player_in_match', 'played', 'team_in_match'),\n",
        "    ('team_in_match', 'team_instance_rev', 'team'),\n",
        "    ('team', 'team_instance', 'team_in_match'),\n",
        "    ('team_in_match', 'result', 'team_in_match')\n",
        "]\n",
        "\n",
        "metapath_homo = [\n",
        "    ('team', 'team_instance', 'team_in_match'),\n",
        "    ('team_in_match', 'played_rev', 'player_in_match'),\n",
        "    ('player_in_match', 'player_instance_rev', 'player')\n",
        "]\n",
        "\n",
        "all_used_loss = [\n",
        "    torch.nn.CrossEntropyLoss(),\n",
        "    torch.nn.L1Loss(),\n",
        "    torch.nn.MSELoss(),\n",
        "    torch.nn.CrossEntropyLoss(),\n",
        "    torch.nn.KLDivLoss()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAP3-r4DD0U5"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRyuNWZAFELV"
      },
      "source": [
        "### Data definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k7WoWjMJFGVT"
      },
      "outputs": [],
      "source": [
        "data_options = [\"test\", \"data\"]\n",
        "data_file = data_options[0]\n",
        "win_value = 1.0\n",
        "loss_value = -1.0\n",
        "tie_value = (win_value + loss_value)/2\n",
        "\n",
        "training = -1\n",
        "validate = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLoR1c-2GGun"
      },
      "source": [
        "### Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v857MBSRGIAP"
      },
      "outputs": [],
      "source": [
        "epochs = 500\n",
        "embedding_size = 10\n",
        "hidden_size = 50\n",
        "out_size = 20\n",
        "layers = 10\n",
        "\n",
        "lr = 0.001\n",
        "dropout_p = 0.0\n",
        "Diff = True\n",
        "Tie = True\n",
        "crit = all_used_loss[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utTRzV2s254U"
      },
      "source": [
        "# Analizing scraped data and create graph\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN83x5Kyt_-s"
      },
      "source": [
        "## Get Zipped test.json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hdczE6M5uFQd"
      },
      "outputs": [],
      "source": [
        "with requests.get(f\"https://github.com/JasaZnidar/totalwaterpolo-web-scraper/raw/master/{data_file}.zip\", ) as r:\n",
        "  ZipFile(BytesIO(r.content), \"r\").extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIb_W7__9gwk"
      },
      "source": [
        "## Get scraped data from github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cvzBR3WG3F7G"
      },
      "outputs": [],
      "source": [
        "# open raw data scraped from the website\n",
        "with open(f\"/content/{data_file}.json\") as f:\n",
        "    scraped_data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUCmRM4IpJBF"
      },
      "source": [
        "## Data generating function\n",
        "We will create a function that will create HeteroData from scraped data before a selected date. This will be used to create training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfTaSYJuyRhW"
      },
      "source": [
        "### player_in_match functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "S8ZhkBKFvtWZ"
      },
      "outputs": [],
      "source": [
        "def average(history: list[list[float]]) -> list[float]:\n",
        "  ret = [0]*len(history[0])\n",
        "\n",
        "  # sum up all values\n",
        "  for match in history:\n",
        "    for i in range(len(match)):\n",
        "      ret[i] += match[i]\n",
        "\n",
        "  # divide to get average\n",
        "  if len(history) > 0:\n",
        "    for i in range(len(ret)):\n",
        "      ret[i] /= len(history)\n",
        "\n",
        "  return ret\n",
        "\n",
        "def average_last_n(history: list[list[float]], n: int = 20) -> list[float]:\n",
        "  ret = [0]*len(history[0])\n",
        "  n = min(n, len(history))\n",
        "  history = history[-n:]\n",
        "\n",
        "  # sum up all values\n",
        "  for match in history:\n",
        "    for i in range(len(match)):\n",
        "      ret[i] += match[i]\n",
        "\n",
        "  # divide to get average\n",
        "  if n > 0:\n",
        "    for i in range(len(ret)):\n",
        "      ret[i] /= n\n",
        "\n",
        "  return ret\n",
        "\n",
        "def function_weight(history: list[list[float]], f: Callable = lambda x: 1/x) -> list[float]:\n",
        "  ret = [0]*len(history[0])\n",
        "\n",
        "\n",
        "  # sum up all values\n",
        "  n = len(history)\n",
        "  weight_sum = 0\n",
        "  for m in range(n):\n",
        "    weight = f(n-m)\n",
        "    weight_sum += weight\n",
        "    for i in range(len(history[m])):\n",
        "      ret[i] += history[m][i] * weight\n",
        "\n",
        "  # normalize with weight sum\n",
        "  if weight_sum > 0:\n",
        "    for i in range(len(ret)):\n",
        "      ret[i] /= weight_sum\n",
        "\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0mMc5H924yA"
      },
      "source": [
        "### Graph creation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ADqYuU2r_0As"
      },
      "outputs": [],
      "source": [
        "def createData(\n",
        "    data: dict,\n",
        "    start: int=0,\n",
        "    stop: int=-1,\n",
        "    instanceCalculator: Callable=average,\n",
        "    combineCalculator: Callable=lambda x: torch.mean(torch.Tensor(x), dim=0),\n",
        "    diff: bool=False,\n",
        "    skipTie: bool=False\n",
        "    ) -> HeteroData:\n",
        "  global win_value, loss_value, tie_value\n",
        "\n",
        "  # data\n",
        "  ret_hetero_data = HeteroData()\n",
        "\n",
        "  # constants\n",
        "  home_value = 1.0\n",
        "  away_value = -1.0\n",
        "\n",
        "\n",
        "  #=============================================================================\n",
        "  # Create player_matrix for player node\n",
        "  #=============================================================================\n",
        "  max_player_id = max([int(id) for id in data['players'].keys()])\n",
        "  player_dim=5\n",
        "  player_matrix = torch.zeros(max_player_id, player_dim, dtype=torch.float32)\n",
        "  all_player_data = {}\n",
        "\n",
        "  for id in data['players'].keys():\n",
        "    index = int(id) - 1\n",
        "    player_data = data['players'][id]\n",
        "    all_player_data[id] = {\n",
        "        \"history\": [],    # [[goals, shots, assists, blocks, saves, exclusions, penalties, suspensions, brutalities, sprints won, sprints],...]\n",
        "        \"last index\": -1    # last index, referencing this them in playerInMatch node\n",
        "    }\n",
        "\n",
        "    player_matrix[index, 0] = player_data['birth']\n",
        "    player_matrix[index, 1] = 1 if player_data['hand'] == 'R' else -1 if player_data['hand'] == \"L\" else 0\n",
        "    player_matrix[index, 2] = player_data['height'] if player_data['height'] else 0\n",
        "    match player_data['position']:\n",
        "      case '':\n",
        "        player_matrix[index, 3] = 0\n",
        "      case 'Goalkeeper':\n",
        "        player_matrix[index, 3] = 1\n",
        "      case 'Driver':\n",
        "        player_matrix[index, 3] = 2\n",
        "      case 'Left Driver':\n",
        "        player_matrix[index, 3] = 3\n",
        "      case 'Right Driver':\n",
        "        player_matrix[index, 3] = 4\n",
        "      case 'Central Defender':\n",
        "        player_matrix[index, 3] = 5\n",
        "      case 'Left Winger':\n",
        "        player_matrix[index, 3] = 6\n",
        "      case 'Right Winger':\n",
        "        player_matrix[index, 3] = 7\n",
        "      case 'Center Forward':\n",
        "        player_matrix[index, 3] = 8\n",
        "    player_matrix[index, 4] = player_data['weight'] if player_data['weight'] else 0\n",
        "\n",
        "  del player_data, index\n",
        "\n",
        "\n",
        "  #=============================================================================\n",
        "  # Matrices that will define the graph\n",
        "  #=============================================================================\n",
        "  # player in a match (played_in_match)\n",
        "  playerInMatch_dim = 11\n",
        "  playerInMatch_matrix = torch.empty(0, playerInMatch_dim, dtype=torch.float32)\n",
        "\n",
        "  # team (team)\n",
        "  numOfTeams = 0\n",
        "\n",
        "  # team in a match (team_in_match)\n",
        "  teamInMatch_dim = 3\n",
        "  teamInMatch_matrix = torch.empty(0, teamInMatch_dim, dtype=torch.float32)\n",
        "\n",
        "  # player instance relation (player, player_instance, played_in_match)\n",
        "  playerInstance_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "\n",
        "  # played relation (played_in_match, played, team_in_match)\n",
        "  played_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "  played_attr = torch.empty(1, 0, dtype=torch.float32)\n",
        "\n",
        "  # team participated in a match (team, team_instance, team_in_match)\n",
        "  teamInstance_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "\n",
        "  # match result (team_in_match, result, team_in_match)\n",
        "  result_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "  result_attr = torch.empty(1, 0, dtype=torch.float32)\n",
        "  result_weight = torch.empty(1, 0, dtype=torch.float32)\n",
        "\n",
        "\n",
        "  #=============================================================================\n",
        "  # Other data\n",
        "  #=============================================================================\n",
        "  all_team_data = {}   # key => {data, last_index, index}\n",
        "\n",
        "\n",
        "  #=============================================================================\n",
        "  # Sort matches in order of date, and filter out the matches that happened\n",
        "  # after the specified date\n",
        "  #=============================================================================\n",
        "  # filter out matches\n",
        "  sorted_match_ids = []\n",
        "  breakpoint_match_id = (\"\", -1)\n",
        "  for match_id in data['matches']:\n",
        "    if 'date' in data['matches'][match_id]:\n",
        "      sorted_match_ids.append((match_id, data['matches'][match_id]['date']))\n",
        "\n",
        "  # sort matches\n",
        "  sorted_match_ids = sorted(sorted_match_ids, key=lambda t: t[1])\n",
        "\n",
        "\n",
        "  #=============================================================================\n",
        "  # Loop through the matches and fill out the matrices\n",
        "  #=============================================================================\n",
        "  for index in range(len(sorted_match_ids)):\n",
        "    # exit loop if enough matches have been added\n",
        "    if result_matrix.shape[1] == stop - start:\n",
        "      break\n",
        "    match_id, _ = sorted_match_ids[index]\n",
        "    match_data = data['matches'][match_id]\n",
        "\n",
        "    # check if match is relevant (at least 7 players in each team)\n",
        "    if len(match_data['lineup']['home']) < 7 or len(match_data['lineup']['away']) < 7:\n",
        "      continue\n",
        "\n",
        "\n",
        "    #===========================================================================\n",
        "    # result of match\n",
        "    #===========================================================================\n",
        "    if index >= start and not (skipTie and match_data['result']['home'] == match_data['result']['away']):\n",
        "      result_matrix = torch.cat((result_matrix, torch.empty((2, 2))), dim=1)\n",
        "      result_attr = torch.cat((result_attr, torch.empty((1, 2))), dim=1)\n",
        "      result_weight = torch.cat((result_weight, torch.empty((1, 2))), dim=1)\n",
        "      if diff:\n",
        "        result_attr[0, -2] = match_data['result']['away'] - match_data['result']['home']\n",
        "        result_attr[0, -1] = match_data['result']['home'] - match_data['result']['away']\n",
        "      else:\n",
        "        if match_data['result']['home'] > match_data['result']['away']:\n",
        "          result_attr[0, -2] = loss_value\n",
        "          result_attr[0, -1] = win_value\n",
        "        elif match_data['result']['home'] < match_data['result']['away']:\n",
        "          result_attr[0, -2] = win_value\n",
        "          result_attr[0, -1] = loss_value\n",
        "        else:\n",
        "          result_attr[0, -2] = tie_value\n",
        "          result_attr[0, -1] = tie_value\n",
        "      result_weight[0, -2] = abs(match_data['result']['away'] - match_data['result']['home'])\n",
        "      result_weight[0, -1] = result_weight[0, -2]\n",
        "\n",
        "\n",
        "    #===========================================================================\n",
        "    # loop through the teams\n",
        "    #===========================================================================\n",
        "    for team in ['home', 'away']:\n",
        "      # create teamInMatch\n",
        "      team_key = match_data['name'][team]\n",
        "\n",
        "      #=========================================================================\n",
        "      # create/update all_team_data\n",
        "      #=========================================================================\n",
        "      # if there is no instance of the team, we need a new team\n",
        "      if not team_key in all_team_data:\n",
        "        all_team_data[team_key] = {\n",
        "            \"data\": [0]*teamInMatch_dim,    # [wins, matches, home/away]\n",
        "            \"last index\": -1,   # last index, referencing this them in teamInMatch node\n",
        "            \"index\": numOfTeams   # index for team node\n",
        "        }\n",
        "\n",
        "        # add new team\n",
        "        numOfTeams += 1\n",
        "\n",
        "      # update home/away status\n",
        "      all_team_data[team_key]['data'][-1] = home_value if team == \"home\" else away_value\n",
        "\n",
        "\n",
        "      #=========================================================================\n",
        "      # create team_in_match data instance\n",
        "      #=========================================================================\n",
        "      if index >= start:\n",
        "        # add new teamInMatch\n",
        "        all_team_data[team_key]['last index'] = int(teamInMatch_matrix.size(dim=0))\n",
        "        teamInMatch_matrix = torch.cat((teamInMatch_matrix, torch.Tensor([all_team_data[team_key]['data']])), dim=0)\n",
        "\n",
        "        # connect teamInMatch to enemy teamInMatch\n",
        "        result_matrix[0 if team == \"home\" else 1, -2] = all_team_data[team_key]['last index']\n",
        "        result_matrix[0 if team == \"away\" else 1, -1] = all_team_data[team_key]['last index']\n",
        "\n",
        "        # connect team to teamInMatch\n",
        "        teamInstance_matrix = torch.cat((teamInstance_matrix, torch.Tensor([[all_team_data[team_key]['index']], [all_team_data[team_key]['last index']]])), dim=1)\n",
        "\n",
        "\n",
        "      #=========================================================================\n",
        "      # update all_team_data\n",
        "      #=========================================================================\n",
        "      # if won, increase number of wins\n",
        "      if match_data['result'][team] > match_data['result']['away' if team == \"home\" else 'home']:\n",
        "        all_team_data[team_key]['data'][0] += 1\n",
        "\n",
        "      # increase number of matches\n",
        "      all_team_data[team_key]['data'][1] += 1\n",
        "\n",
        "\n",
        "      #=========================================================================\n",
        "      # loop through the lineup\n",
        "      #=========================================================================\n",
        "      for player_num in match_data['lineup'][team]:\n",
        "        player_id = match_data['lineup'][team][player_num]['id']\n",
        "\n",
        "\n",
        "        #=======================================================================\n",
        "        # add and connect new nodes together\n",
        "        #=======================================================================\n",
        "        if index >= start:\n",
        "          # add new playerInMatch\n",
        "          if not player_id in all_player_data:\n",
        "            all_player_data[player_id] = {\n",
        "                \"history\": [],\n",
        "                \"last index\": -1\n",
        "            }\n",
        "          if all_player_data[player_id]['history'] == []:\n",
        "            playerInMatch_tensor = torch.Tensor([[0]*playerInMatch_dim])\n",
        "          else:\n",
        "            playerInMatch_tensor = torch.Tensor([ instanceCalculator( all_player_data[player_id]['history'] ) ])\n",
        "          all_player_data[player_id]['last index'] = playerInMatch_matrix.size(dim=0)\n",
        "          playerInMatch_matrix = torch.cat((playerInMatch_matrix, playerInMatch_tensor), dim=0)\n",
        "          playerInMatch_index = playerInMatch_matrix.size(dim=0) - 1\n",
        "\n",
        "          # connect player to playerInMatch\n",
        "          playerInstance_matrix = torch.cat((playerInstance_matrix, torch.Tensor([[int(player_id)-1], [all_player_data[player_id]['last index']]])), dim=1)\n",
        "\n",
        "          # connect playerInMatch to teamInMatch\n",
        "          played_matrix = torch.cat((played_matrix, torch.Tensor([[all_player_data[player_id]['last index']], [all_team_data[team_key]['last index']]])), dim=1)\n",
        "          played_attr = torch.cat((played_attr, torch.Tensor([[0 if player_num == \"1\" or player_num == \"13\" else 1]])), dim=1)\n",
        "\n",
        "        # add all_player_data history for this match\n",
        "        all_player_data[player_id]['history'].append([0] * playerInMatch_dim)\n",
        "\n",
        "\n",
        "    #===========================================================================\n",
        "    # update data with this match\n",
        "    #===========================================================================\n",
        "    # go throught ALL plays and update cumulative_all_player_data and cumulative_all_team_data\n",
        "    for play in match_data['plays']:\n",
        "      # check if a player was marked\n",
        "      if play['player_1'] == 0:\n",
        "        continue\n",
        "\n",
        "      # find teams\n",
        "      team_1 = play['team']\n",
        "      team_2 = \"home\" if team_1 == \"away\" else \"away\"\n",
        "\n",
        "      # find players who participated in the play\n",
        "      try:\n",
        "        id_1 = match_data['lineup'][team_1][str(play['player_1'])]['id']\n",
        "      except Exception as ex:\n",
        "        print(match_id, team_1, match_data['name'][team_1])\n",
        "        #print(json.dumps(match_data['lineup'][team_1], sort_keys=True, indent=4))\n",
        "        print(json.dumps(play, sort_keys=True, indent=4))\n",
        "        raise ex\n",
        "      id_2 = [0, 0] # depending on the play, the second player could be from the same team (first value is the opposing team)\n",
        "      if not play['player_2'] == 0:\n",
        "        if str(play['player_2']) in match_data['lineup'][team_2]:\n",
        "          id_2[0] = match_data['lineup'][team_2][str(play['player_2'])]['id']\n",
        "        if str(play['player_2']) in match_data['lineup'][team_1]:\n",
        "          id_2[1] = match_data['lineup'][team_1][str(play['player_2'])]['id']\n",
        "\n",
        "      # detect play type\n",
        "      if \"goal scored\" in play['action']:\n",
        "        # goals\n",
        "        all_player_data[id_1]['history'][-1][0] += 1\n",
        "        # shots\n",
        "        all_player_data[id_1]['history'][-1][1] += 1\n",
        "        if not id_2[1] == 0:\n",
        "          # assists\n",
        "          all_player_data[id_1]['history'][-1][2] += 1\n",
        "      elif \"exclusion\" in play['action']:\n",
        "        # exclusion\n",
        "        all_player_data[id_1]['history'][-1][5] += 1\n",
        "      elif \"penalty foul\" in play['action']:\n",
        "        # penalty\n",
        "        all_player_data[id_1]['history'][-1][6] += 1\n",
        "      elif \"shot missed\" in play['action']:\n",
        "        # shots\n",
        "        all_player_data[id_1]['history'][-1][1] += 1\n",
        "      elif \"shot saved\" in play['action']:\n",
        "        # shots\n",
        "        all_player_data[id_1]['history'][-1][1] += 1\n",
        "      elif \"shot blocked\" in play['action']:\n",
        "        # shots\n",
        "        all_player_data[id_1]['history'][-1][1] += 1\n",
        "        if not id_2[0] == 0:\n",
        "          # blocks\n",
        "          all_player_data[id_2]['history'][-1][3] += 1\n",
        "      elif \"suspention\" in play['action']:\n",
        "        # suspensions\n",
        "        all_player_data[id_1]['history'][-1][7] += 1\n",
        "      elif \"brutality\" in play['action']:\n",
        "        # brutalities\n",
        "        all_player_data[id_1]['history'][-1][8] += 1\n",
        "      elif \"sprint won\" in play['action']:\n",
        "        # sprint won\n",
        "        all_player_data[id_1]['history'][-1][9] += 1\n",
        "        # sprint\n",
        "        all_player_data[id_1]['history'][-1][10] += 1\n",
        "        if not id_2[0] == 0:\n",
        "          # sprint\n",
        "          all_player_data[id_2]['history'][-1][10] += 1\n",
        "\n",
        "\n",
        "  #=============================================================================\n",
        "  # save heterogeneus data\n",
        "  #=============================================================================\n",
        "  ret_hetero_data['player'].x = player_matrix\n",
        "  ret_hetero_data['player_in_match'].x = playerInMatch_matrix\n",
        "  ret_hetero_data['team'].num_nodes = numOfTeams\n",
        "  ret_hetero_data['team_in_match'].x = teamInMatch_matrix\n",
        "\n",
        "  ret_hetero_data['player', 'player_instance', 'player_in_match'].edge_index = playerInstance_matrix.type(torch.long)\n",
        "  ret_hetero_data['player_in_match', 'player_instance_rev', 'player'].edge_index = playerInstance_matrix.flip([0]).type(torch.long)\n",
        "\n",
        "  ret_hetero_data['player_in_match', 'played', 'team_in_match'].edge_index = played_matrix.type(torch.long)\n",
        "  ret_hetero_data['player_in_match', 'played', 'team_in_match'].edge_attr = played_attr\n",
        "  ret_hetero_data['team_in_match', 'played_rev', 'player_in_match'].edge_index = played_matrix.flip([0]).type(torch.long)\n",
        "  ret_hetero_data['team_in_match', 'played_rev', 'player_in_match'].edge_attr = played_attr\n",
        "\n",
        "  ret_hetero_data['team', 'team_instance', 'team_in_match'].edge_index = teamInstance_matrix.type(torch.long)\n",
        "  ret_hetero_data['team_in_match', 'team_instance_rev', 'team'].edge_index = teamInstance_matrix.flip([0]).type(torch.long)\n",
        "\n",
        "  ret_hetero_data['team_in_match', 'result', 'team_in_match'].edge_index = result_matrix.type(torch.long)\n",
        "  ret_hetero_data['team_in_match', 'result', 'team_in_match'].edge_attr = result_attr\n",
        "  ret_hetero_data['team_in_match', 'result', 'team_in_match'].edge_weight = result_weight\n",
        "\n",
        "  return ret_hetero_data\n",
        "\n",
        "def numberOfValidMatches(data: dict) -> int:\n",
        "  numOfMatches = 0\n",
        "  for match_id in data['matches']:\n",
        "    if len(data['matches'][match_id]['lineup']['home']) < 7 or len(data['matches'][match_id]['lineup']['away']) < 7:\n",
        "      continue\n",
        "    numOfMatches += 1\n",
        "\n",
        "  return numOfMatches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGflFDiyeT9P"
      },
      "source": [
        "### Split data into training and validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-xP4QJPeobL"
      },
      "source": [
        "Values to define the scope of the training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cpVJm9J_eafv"
      },
      "outputs": [],
      "source": [
        "instance_function = average\n",
        "combination_function = lambda x: torch.mean(torch.Tensor(x), dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3fAZGh2evKU"
      },
      "source": [
        "If train or validate are not bigger then 0, their values are addapted acordingly to fully utilize the avaliable data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5uG5xxTe1C6",
        "outputId": "f04d4ce1-651b-411b-fea6-0a6055cb1bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 0 - 4373\n",
            "validate: 4374 - 4384\n"
          ]
        }
      ],
      "source": [
        "numOfMatches = numberOfValidMatches(scraped_data)\n",
        "\n",
        "if training <= 0 and validate <= 0:\n",
        "  validate = 1\n",
        "  training = numOfMatches - 1\n",
        "elif training <= 0:\n",
        "  training = numOfMatches - validate\n",
        "elif validate <= 0:\n",
        "  validate = numOfMatches - training\n",
        "\n",
        "if training < 0 or validate < 0:\n",
        "  training = numOfMatches - 2\n",
        "  validate = 2\n",
        "\n",
        "print(f\"train: 0 - {training-1}\")\n",
        "print(f\"validate: {training} - {training + validate}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_q5a5KoX2rFp"
      },
      "outputs": [],
      "source": [
        "hetero_train_data = createData(\n",
        "    scraped_data,\n",
        "    stop=training,\n",
        "    instanceCalculator=instance_function,\n",
        "    combineCalculator=combination_function,\n",
        "    diff=Diff,\n",
        "    skipTie=not Tie\n",
        ")\n",
        "\n",
        "hetero_val_data = createData(\n",
        "    scraped_data,\n",
        "    start=training,\n",
        "    stop=(training + validate),\n",
        "    instanceCalculator=instance_function,\n",
        "    combineCalculator=combination_function,\n",
        "    diff=Diff,\n",
        "    skipTie=not Tie\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB9prObutrWq"
      },
      "source": [
        "### Transform to homogeneus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qMv-ObVOtwop"
      },
      "outputs": [],
      "source": [
        "def toHomo(data: HeteroData, size: int = 20) -> Data:\n",
        "  global metapath_homo\n",
        "\n",
        "  path = nn.MetaPath2Vec(\n",
        "      edge_index_dict = {edge : data[edge].edge_index for edge in data.metadata()[1]},\n",
        "      embedding_dim = embedding_size,\n",
        "      metapath = metapath_homo,\n",
        "      walks_per_node = 13,\n",
        "      walk_length = 3,\n",
        "      context_size = 4\n",
        "  ).to(device)\n",
        "\n",
        "  # dict: team_in_match -> team\n",
        "  team_dict = {team_instance[1].item(): team_instance[0].item() for team_instance in data['team', 'team_instance', 'team_in_match'].edge_index.T}\n",
        "  edge_index = torch.Tensor([[team_dict[result[0].item()], team_dict[result[1].item()]] for result in data['team_in_match', 'result', 'team_in_match'].edge_index.T]).T.type(torch.long)\n",
        "\n",
        "  homoData = Data();\n",
        "  homoData.x = path.forward('team')\n",
        "  homoData.edge_index = edge_index\n",
        "  homoData.edge_attr = data['team_in_match', 'result', 'team_in_match'].edge_attr\n",
        "\n",
        "  return homoData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jcT74uzKy_My"
      },
      "outputs": [],
      "source": [
        "homo_train_data = toHomo(hetero_train_data)\n",
        "homo_val_data = toHomo(hetero_val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQFhdJpZxlIV"
      },
      "source": [
        "### Testing: home always wins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "st4LyWyGxpzS"
      },
      "outputs": [],
      "source": [
        "def homeAlwaysWins():\n",
        "  global homo_train_data, homo_val_data\n",
        "\n",
        "  homo_train_data = Data()\n",
        "  homo_train_data.x = torch.Tensor(\n",
        "      [[11.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 6.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 7.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 2.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 0.0/ 8.0] + [0.0]*(embedding_size - 1)]\n",
        "  )\n",
        "  homo_train_data.edge_index = torch.Tensor(\n",
        "      [[1, 2, 3, 4, 0, 4, 2, 3, 0, 3, 1, 4, 0, 1, 2, 4, 0, 2, 1, 3, 1, 2, 3, 4, 0, 4, 2, 3, 0, 3, 1, 4, 0, 1, 2, 4, 0, 2, 1, 3],\n",
        "       [2, 1, 4, 3, 4, 0, 3, 2, 3, 0, 4, 1, 1, 0, 4, 2, 2, 0, 3, 1, 2, 1, 4, 3, 4, 0, 3, 2, 3, 0, 4, 1, 1, 0, 4, 2, 2, 0, 3, 1]]\n",
        "  ).type(torch.long)\n",
        "  homo_train_data.edge_attr = torch.Tensor(\n",
        "      [[win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value]]\n",
        "  )\n",
        "\n",
        "  homo_val_data = Data()\n",
        "  homo_val_data.x = torch.Tensor(\n",
        "      [[11.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 6.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 7.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 2.0/11.0] + [0.0]*(embedding_size - 1),\n",
        "       [ 0.0/ 8.0] + [0.0]*(embedding_size - 1)]\n",
        "  )\n",
        "  homo_val_data.edge_index = torch.Tensor(\n",
        "      [[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
        "       [1, 0, 3, 2, 1, 0, 3, 2, 1, 0, 3, 2]]\n",
        "  ).type(torch.long)\n",
        "  homo_val_data.edge_attr = torch.Tensor(\n",
        "      [[win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value, win_value, loss_value]]\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5-mQqCuzGF9"
      },
      "source": [
        "### Testing: team A custom win rate of matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VRrkEnQizU4U"
      },
      "outputs": [],
      "source": [
        "def AWinsRatio(ratio: int = 9, num_of_matches: int = 100):\n",
        "  global homo_train_data, homo_val_data\n",
        "\n",
        "  # train\n",
        "  homo_train_data = Data()\n",
        "  homo_train_data.x = torch.Tensor(\n",
        "      [[ratio/(ratio + 1)] + [0.0]*(embedding_size - 1),\n",
        "       [    1/(ratio + 1)] + [0.0]*(embedding_size - 1)]\n",
        "  )\n",
        "  homo_train_data.edge_index = torch.Tensor(\n",
        "      [[0, 1]*num_of_matches,\n",
        "       [1, 0]*num_of_matches]\n",
        "  ).type(torch.long)\n",
        "  homo_train_data.edge_attr = torch.Tensor(\n",
        "      [[win_value, loss_value]*num_of_matches]\n",
        "  )\n",
        "\n",
        "  for i in range(ratio, num_of_matches, ratio + 1):\n",
        "    homo_train_data.edge_attr[0, (2*i):(2*i + 2)] = torch.Tensor([loss_value, win_value])\n",
        "\n",
        "  # validation\n",
        "  homo_val_data = Data()\n",
        "  homo_val_data.x = torch.Tensor(\n",
        "      [[ratio/(ratio + 1)] + [0.0]*(embedding_size - 1),\n",
        "       [    1/(ratio + 1)] + [0.0]*(embedding_size - 1)]\n",
        "  )\n",
        "  homo_val_data.edge_index = torch.Tensor(\n",
        "      [[0, 1]*(ratio + 1),\n",
        "       [1, 0]*(ratio + 1)]\n",
        "  ).type(torch.long)\n",
        "\n",
        "  homo_val_data.edge_attr = torch.Tensor(\n",
        "      [[win_value, loss_value]*(ratio + 1)]\n",
        "  )\n",
        "  homo_val_data.edge_attr[0, -2:] = torch.Tensor([loss_value, win_value])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbAue-pAHJ96"
      },
      "source": [
        "### Selecting test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3mmGFfHJHMsJ"
      },
      "outputs": [],
      "source": [
        "#AWinsRatio(9, 1000)\n",
        "homeAlwaysWins()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd1yf4Tn0sKT"
      },
      "source": [
        "# Machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model preparations"
      ],
      "metadata": {
        "id": "YxMnRtdE6vQC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY6Ui5v-Cy27"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ClDDm119C0l2"
      },
      "outputs": [],
      "source": [
        "\"\"\"class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_home: torch.Tensor, x_away: torch.Tensor, edge_label_index: torch.Tensor) -> torch.Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_winner = x_home[edge_label_index[0]]\n",
        "        edge_feat_loser = x_away[edge_label_index[1]]\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_winner * edge_feat_loser).sum(dim=-1)\"\"\"\n",
        "\n",
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self, input: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin = torch.nn.Linear(input, 1)\n",
        "\n",
        "    def forward(self, x_home: torch.Tensor, x_away: torch.Tensor, edge_label_index: torch.Tensor) -> torch.Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_winner = x_home[edge_label_index[0]]\n",
        "        edge_feat_loser = x_away[edge_label_index[1]]\n",
        "\n",
        "        input = torch.cat((edge_feat_winner, edge_feat_loser), dim=1)\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return self.lin(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLhx7YnwvJ_4"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4r0O3L_jvM4m"
      },
      "outputs": [],
      "source": [
        "class Embedding(torch.nn.Module):\n",
        "    def __init__(self, metapath: list, size: int = 20) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.vec = nn.MetaPath2Vec(\n",
        "            edge_index_dict = {edge : hetero_train_data[edge].edge_index for edge in hetero_train_data.metadata()[1]},\n",
        "            embedding_dim = embedding_size,\n",
        "            metapath = metapath,\n",
        "            walk_length = 20,\n",
        "            context_size = 10,\n",
        "            walks_per_node = size\n",
        "        )\n",
        "\n",
        "    def forward(self, node: str) -> torch.Tensor:\n",
        "      return self.vec(node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW0eaun_bRHk"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Support functions"
      ],
      "metadata": {
        "id": "ahKxTgQKF7Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regToRoc(pred: torch.Tensor, ground: torch.Tensor, target: int = 0, targets: list[int] = [win_value, tie_value, loss_value]):\n",
        "  # normalize pred to ground truth\n",
        "  pred = pred / torch.abs(ground)\n",
        "\n",
        "  # diff to target\n",
        "  diff = torch.abs(pred - targets[target])\n",
        "\n",
        "  # normalize diff\n",
        "  diff = diff / max([abs(val - targets[target]) for val in targets])\n",
        "\n",
        "  # classify grount_truth\n",
        "  classify = ground == targets[target]\n",
        "  classify = classify.type(torch.float32)\n",
        "\n",
        "  return (diff, classify)"
      ],
      "metadata": {
        "id": "ojY2p5tXGD7Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AUC():\n",
        "  def __init__(self, metric):\n",
        "    self.metric = metric()\n",
        "\n",
        "  def update(self, pred: torch.Tensor, ground_truth: torch.Tensor):\n",
        "    pred = pred\n",
        "    ground_truth = ground_truth\n",
        "\n",
        "    pred, ground_truth = regToRoc(pred, ground_truth, 0)\n",
        "\n",
        "    self.metric.update(pred.T, ground_truth.T)\n",
        "\n",
        "  def compute(self):\n",
        "    return self.metric.compute()\n",
        "\n",
        "  def to(self, device: str):\n",
        "    self.metric.to(device)"
      ],
      "metadata": {
        "id": "AgM4EfkETMN1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main class"
      ],
      "metadata": {
        "id": "sXjdRfifF4mP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g6FAQW2-UdzZ"
      },
      "outputs": [],
      "source": [
        "metrics = [M.R2Score(), M.MeanSquaredError(), AUC(M.BinaryAUPRC)]\n",
        "\n",
        "class Metrics():\n",
        "  def __init__(self, device: str = 'cpu', metrics: list = metrics):\n",
        "    self.device = device\n",
        "    for m in metrics:\n",
        "      m.to(device)\n",
        "    self.metrics = metrics\n",
        "\n",
        "  def update(self, pred: torch.Tensor, ground_truth: torch.Tensor):\n",
        "    pred = pred.to(self.device)\n",
        "    ground_truth = ground_truth.to(self.device)\n",
        "\n",
        "    for metric in self.metrics:\n",
        "      metric.update(pred, ground_truth)\n",
        "\n",
        "  def compute(self):\n",
        "    ret = {}\n",
        "\n",
        "    for metric in self.metrics:\n",
        "      ret[metric.__class__.__name__] = metric.compute()\n",
        "\n",
        "      if not ret[metric.__class__.__name__].shape == torch.Size([]):\n",
        "        ret[metric.__class__.__name__] = torch.reshape(ret[metric.__class__.__name__], [])\n",
        "\n",
        "    return ret\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6_B8ZZ_3tqfu"
      },
      "outputs": [],
      "source": [
        "def drawData(data: list[dict]) -> None:\n",
        "  keys = [key for key in data[0].keys()]\n",
        "  num = len(keys)\n",
        "\n",
        "  _, ax = plt.subplots(1, num, figsize=(num*epochs/100 + 3, 4))\n",
        "\n",
        "  for i in range(num):\n",
        "    ax[i].set_title(keys[i])\n",
        "\n",
        "    ax[i].plot(range(len(data)), [data[x][keys[i]].item() for x in range(len(data))])\n",
        "\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def printResults(L: torch.Tensor):\n",
        "  l = torch.reshape(L, (-1,)).tolist()\n",
        "  for i in l:\n",
        "    print(f\"{i:8.4f} \", end=\"\")\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "o2g-Cn3DS8ei"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLoss(loss_data: list[float]):\n",
        "  plt.plot(range(len(loss_data)), loss_data)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "PKMALfBtSS0_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydDxJlvA53dw"
      },
      "source": [
        "### Basic module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XFSBHwy559fq"
      },
      "outputs": [],
      "source": [
        "class basicModule(torch.nn.Module):\n",
        "  def __init__(self, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.lin = torch.nn.Linear(2, 1).to(self.device)\n",
        "\n",
        "  def forward(self, edge, edge_index):\n",
        "    x = torch.zeros([edge_index.shape[1], 2])\n",
        "    x[:, 0] = edge[edge_index[0], 2]\n",
        "    x[:, 1] = edge[edge_index[1], 2]\n",
        "\n",
        "    x = self.lin(x.to(self.device))\n",
        "    x = x.relu()\n",
        "    x = F.dropout(x, p=dropout_p, training=self.training)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1UuxaWEbpbk"
      },
      "source": [
        "### Basic Linear module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ylzZsHCtbryQ"
      },
      "outputs": [],
      "source": [
        "class basicLinearModule(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_channels=1, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "    self.lin.to(self.device)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x.to(self.device)\n",
        "\n",
        "    x = self.lin(x)\n",
        "    x = x.relu()\n",
        "    x = F.dropout(x, p=dropout_p, training=self.training)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0-Hkkxv-9ih"
      },
      "source": [
        "#### Supporting functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oB1ZnmXh-4v4"
      },
      "outputs": [],
      "source": [
        "# Average data for team based on players in the team\n",
        "def getTeamAverage(played_dict: dict[int, list[int]], player_data: torch.tensor, teamInMatch_index: int):\n",
        "  # get all playerInMatch indexes\n",
        "  playerInMatch_list = played_dict[teamInMatch_index]\n",
        "\n",
        "  # get all playerInMatch data\n",
        "  playerInMatch_data = torch.empty((0, player_data.shape[1]), dtype=player_data.dtype)\n",
        "  for i in playerInMatch_list:\n",
        "    playerInMatch_data = torch.cat((playerInMatch_data, torch.unsqueeze(player_data[i, :], dim=0)))\n",
        "  #torch.Tensor([player_data[i] for i in playerInMatch_list])\n",
        "\n",
        "  playerInMatch_avg = torch.mean(playerInMatch_data, dim=0)\n",
        "\n",
        "  return playerInMatch_avg\n",
        "\n",
        "# create input data\n",
        "def createLinInput(data: HeteroData):\n",
        "  data = data.to('cpu')\n",
        "\n",
        "  # create dict for players in a match\n",
        "  played_dict = {}\n",
        "  for i in range(data['player_in_match', 'played', 'team_in_match'].edge_index.shape[1]):\n",
        "    key = data['player_in_match', 'played', 'team_in_match'].edge_index[1, i].item()\n",
        "    value = data['player_in_match', 'played', 'team_in_match'].edge_index[0, i].item()\n",
        "    if key in played_dict:\n",
        "      played_dict[key].append(value)\n",
        "    else:\n",
        "      played_dict[key] = [value]\n",
        "\n",
        "  # prepare input\n",
        "  home_x = []\n",
        "  numOfMatches = data['team_in_match', 'result', 'team_in_match'].edge_index.shape[1]\n",
        "  home_x = torch.empty((numOfMatches, data['player_in_match'].x.shape[1]))\n",
        "  away_x = torch.empty((numOfMatches, data['player_in_match'].x.shape[1]))\n",
        "  for i in range(numOfMatches):\n",
        "    home_x[i, :] = getTeamAverage(played_dict, data['player_in_match'].x, data['team_in_match', 'result', 'team_in_match'].edge_index[0, i].item())\n",
        "    away_x[i, :] = getTeamAverage(played_dict, data['player_in_match'].x, data['team_in_match', 'result', 'team_in_match'].edge_index[1, i].item())\n",
        "\n",
        "  # finalize input\n",
        "  input = torch.cat((home_x, away_x), dim=1)\n",
        "\n",
        "  return input.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6mEs7cHcx51"
      },
      "source": [
        "### GCN module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XewxSir-1aRy"
      },
      "outputs": [],
      "source": [
        "class gcn(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.gcn = torch.nn.ModuleList()\n",
        "\n",
        "    if layers == 1:\n",
        "      self.gcn.append(nn.GCNConv(in_channels, out_channels, add_self_loops=False))\n",
        "    else:\n",
        "      self.gcn.append(nn.GCNConv(in_channels, hidden_channels, add_self_loops=False))\n",
        "      for _ in range(1, layers-1):\n",
        "        self.gcn.append(nn.GCNConv(hidden_channels, hidden_channels, add_self_loops=False))\n",
        "      self.gcn.append(nn.GCNConv(hidden_channels, out_channels, add_self_loops=False))\n",
        "\n",
        "    self.gcn.to(self.device)\n",
        "\n",
        "  def forward(self, x, edge_index, weight):\n",
        "    x.to(self.device)\n",
        "\n",
        "    for module in self.gcn:\n",
        "      x = module(x, edge_index, edge_weight=weight)\n",
        "      x = x.relu()\n",
        "      x = F.dropout(x, p=dropout_p, training=self.training)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBU2khASw9fc"
      },
      "source": [
        "#### Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "AidOb30HxEoj"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.emb = Embedding(metapath).to(self.device)\n",
        "\n",
        "    self.gcn = gcn(in_channels, hidden_channels, out_channels, layers, device).to(self.device)\n",
        "\n",
        "    self.classifier = Classifier(out_channels*2).to(self.device)\n",
        "\n",
        "  def forward(self, data: HeteroData):\n",
        "    data = data.to(self.device)\n",
        "\n",
        "    x = self.emb('team_in_match')\n",
        "\n",
        "    x = self.gcn(x, data[\"team_in_match\", \"result\", \"team_in_match\"].edge_index)\n",
        "\n",
        "    x = self.classifier(x, x, data[\"team_in_match\", \"result\", \"team_in_match\"].edge_index)\n",
        "\n",
        "    x = torch.reshape(x, (1, -1))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCcaPgRAxHm9"
      },
      "source": [
        "#### Homogen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tTg1wq2NxJTt"
      },
      "outputs": [],
      "source": [
        "class homoGCN(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.gcn = gcn(in_channels, hidden_channels, out_channels, layers, device).to(self.device)\n",
        "\n",
        "    self.classifier = Classifier(out_channels*2).to(self.device)\n",
        "\n",
        "  def forward(self, data: Data):\n",
        "    data = data.to(self.device)\n",
        "\n",
        "    x = self.gcn(data.x, data.edge_index, data.edge_weight)\n",
        "\n",
        "    x = self.classifier(x, x, data.edge_index)\n",
        "\n",
        "    x = torch.reshape(x, (1, -1))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzviYSH_pGYW"
      },
      "source": [
        "### GAT Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Na4Yn23JpI_u"
      },
      "outputs": [],
      "source": [
        "class gat(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.gat = torch.nn.ModuleList()\n",
        "\n",
        "    if layers == 1:\n",
        "      self.gat.append(nn.GATConv(in_channels, out_channels, add_self_loops=False))\n",
        "    else:\n",
        "      self.gat.append(nn.GATConv(in_channels, hidden_channels, add_self_loops=False))\n",
        "      for _ in range(1, layers-1):\n",
        "        self.gat.append(nn.GATConv(hidden_channels, hidden_channels, add_self_loops=False))\n",
        "      self.gat.append(nn.GATConv(hidden_channels, out_channels, add_self_loops=False))\n",
        "\n",
        "    self.gat.to(self.device)\n",
        "\n",
        "  def forward(self, x, edge_index, edge_attr):\n",
        "    x.to(self.device)\n",
        "\n",
        "    for module in self.gat:\n",
        "      x = module(x, edge_index, edge_attr)\n",
        "      x = x.relu()\n",
        "      x = F.dropout(x, p=dropout_p, training=self.training)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31UbMviCdi0R"
      },
      "source": [
        "#### Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OIMhX7UZdknf"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.emb = Embedding(metapath).to(self.device)\n",
        "\n",
        "    self.gat = gat(in_channels, hidden_channels, out_channels, layers, device).to(self.device)\n",
        "\n",
        "    self.classifier = Classifier(out_channels*2).to(self.device)\n",
        "\n",
        "  def forward(self, data: HeteroData):\n",
        "    data = data.to(self.device)\n",
        "\n",
        "    x = self.emb('team_in_match')\n",
        "\n",
        "    x = self.gat(x, data[\"team_in_match\", \"result\", \"team_in_match\"].edge_index, data[\"team_in_match\", \"result\", \"team_in_match\"].edge_attr)\n",
        "\n",
        "    x = self.classifier(x, x, data[\"team_in_match\", \"result\", \"team_in_match\"].edge_index)\n",
        "\n",
        "    x = torch.reshape(x, (1, -1))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V7c55wGdn66"
      },
      "source": [
        "#### Homogen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cMKbysN0dq0_"
      },
      "outputs": [],
      "source": [
        "class homoGAT(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.gat = gat(in_channels, hidden_channels, out_channels, layers, device).to(self.device)\n",
        "\n",
        "    self.classifier = Classifier(out_channels*2).to(self.device)\n",
        "\n",
        "  def forward(self, data: Data):\n",
        "    data = data.to(self.device)\n",
        "\n",
        "    x = self.gat(data.x, data.edge_index, data.edge_attr)\n",
        "\n",
        "    x = self.classifier(x, x, data.edge_index)\n",
        "\n",
        "    x = torch.reshape(x, (1, -1))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjGwyEOAnulm"
      },
      "source": [
        "### SAGE module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "49R8gfrJntf2"
      },
      "outputs": [],
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    if layers == 1:\n",
        "      self.gcn = nn.SAGEConv(in_channels, out_channels, add_self_loops=False)\n",
        "    else:\n",
        "      self.gcn = torch.nn.ModuleList()\n",
        "      self.gcn.append(nn.SAGEConv(in_channels, hidden_channels, add_self_loops=False))\n",
        "      for _ in range(1, layers-1):\n",
        "        self.gcn.append(nn.SAGEConv(hidden_channels, hidden_channels, add_self_loops=False))\n",
        "      self.gcn.append(nn.SAGEConv(hidden_channels, out_channels, add_self_loops=False))\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for module in self.gcn:\n",
        "      x = module(x, edge_index)\n",
        "      x = x.relu()\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution preparation"
      ],
      "metadata": {
        "id": "YgpRrXXy6Bt_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXWygaeMj5Xu"
      },
      "source": [
        "### Basic Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "m30eApwATQwV"
      },
      "outputs": [],
      "source": [
        "def BasicModel():\n",
        "  basic = basicModule(device=device)\n",
        "  basicData = []\n",
        "\n",
        "  optimizer = torch.optim.Adam(basic.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = total_examples = 0\n",
        "    basic.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = basic(\n",
        "        hetero_train_data['team_in_match'].x,\n",
        "        hetero_train_data['team_in_match', 'result', 'team_in_match'].edge_index\n",
        "    ).T.to(device)\n",
        "    ground_truth = hetero_train_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "    loss = crit(pred, ground_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validate\n",
        "    basic.eval()\n",
        "    pred = basic(\n",
        "        hetero_val_data['team_in_match'].x,\n",
        "        hetero_val_data['team_in_match', 'result', 'team_in_match'].edge_index\n",
        "    ).T.to(device)\n",
        "    ground_truth = hetero_val_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "\n",
        "    basicMetric = Metrics(device)\n",
        "    basicMetric.update(pred.T, ground_truth.T)\n",
        "    compute = basicMetric.compute()\n",
        "    basicData.append(compute)\n",
        "\n",
        "  for key in compute:\n",
        "    print(f\"{key}: {compute[key]}\")\n",
        "\n",
        "  drawData(basicData)\n",
        "\n",
        "  return pred, ground_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnII2YqMdQ9c"
      },
      "source": [
        "### Linear Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "i-oDsxztdTZ7"
      },
      "outputs": [],
      "source": [
        "def LinearModel():\n",
        "  inputForLinear = createLinInput(hetero_train_data)\n",
        "  basicLinearData = []\n",
        "\n",
        "  basicLinear = basicLinearModule(inputForLinear.shape[1], device=device) # 2*playerInMatch_dim\n",
        "\n",
        "  optimizer = torch.optim.Adam(basicLinear.parameters(), lr=lr)\n",
        "\n",
        "  total_loss = total_examples = 0\n",
        "  basicLinear.train()\n",
        "  optimizer.zero_grad()\n",
        "  pred = basicLinear(\n",
        "      inputForLinear\n",
        "  ).T.to(device)\n",
        "  ground_truth = hetero_train_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "  loss = crit(pred, ground_truth)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # validate\n",
        "  basicLinear.eval()\n",
        "  pred = basicLinear(\n",
        "      hetero_val_data['team_in_match'].x,\n",
        "      hetero_val_data['team_in_match', 'result', 'team_in_match'].edge_index\n",
        "  ).T.to(device)\n",
        "  ground_truth = hetero_val_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "\n",
        "  linearMetric = Metrics(device)\n",
        "  linearMetric.update(pred.T, ground_truth.T)\n",
        "  compute = linearMetric.compute()\n",
        "  basicLinearData.append(compute)\n",
        "\n",
        "  for key in compute:\n",
        "    print(f\"{key}: {compute[key]}\")\n",
        "\n",
        "  drawData(basicLinearData)\n",
        "\n",
        "  return pred, ground_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCjc3rNjj8V6"
      },
      "source": [
        "### GCN Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1ZlESIS3jceS"
      },
      "outputs": [],
      "source": [
        "def GcnModel():\n",
        "  GCNModule = GCN(embedding_size, hidden_size, out_size, layers=layers, device=device)\n",
        "  gcnData = []\n",
        "\n",
        "  optimizer = torch.optim.Adam(GCNModule.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = total_examples = 0\n",
        "    GCNModule.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = GCNModule(hetero_train_data).to(device)\n",
        "    ground_truth = hetero_train_data[\"team_in_match\", \"result\", \"team_in_match\"].edge_attr.to(device)\n",
        "    loss = crit(pred, ground_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validate\n",
        "    GCNModule.eval()\n",
        "    pred = GCNModule(hetero_val_data).to(device)\n",
        "    ground_truth = hetero_val_data[\"team_in_match\", \"result\", \"team_in_match\"].edge_attr.to(device)\n",
        "\n",
        "    gcnMetric = Metrics(device)\n",
        "    gcnMetric.update(pred.T, ground_truth.T)\n",
        "    compute = gcnMetric.compute()\n",
        "    gcnData.append(compute)\n",
        "\n",
        "  for key in compute:\n",
        "    print(f\"{key}: {compute[key]}\")\n",
        "\n",
        "  drawData(gcnData)\n",
        "\n",
        "  return pred, ground_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrdvl6lVyoFb"
      },
      "source": [
        "### Homogen GCN Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5SlJsu9Myqf5"
      },
      "outputs": [],
      "source": [
        "def HomogenGcnModel():\n",
        "  homoGCNModule = homoGCN(embedding_size, hidden_size, out_size, layers=layers, device=device)\n",
        "  homoGcnData = []\n",
        "\n",
        "  optimizer = torch.optim.Adam(homoGCNModule.parameters(), lr=lr)\n",
        "\n",
        "  loss_values = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = total_examples = 0\n",
        "    homoGCNModule.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = homoGCNModule(homo_train_data).to(device)\n",
        "    ground_truth = homo_train_data.edge_attr.to(device)\n",
        "    loss = crit(pred, ground_truth)\n",
        "    loss_values.append(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validate\n",
        "    homoGCNModule.eval()\n",
        "    pred = homoGCNModule(homo_val_data).to(device)\n",
        "    ground_truth = homo_val_data.edge_attr.to(device)\n",
        "\n",
        "    homoGcnMetric = Metrics(device)\n",
        "    homoGcnMetric.update(pred.T, ground_truth.T)\n",
        "    compute = homoGcnMetric.compute()\n",
        "    homoGcnData.append(compute)\n",
        "\n",
        "  #for key in compute:\n",
        "  #  print(f\"{key}: {compute[key]}\")\n",
        "\n",
        "  #drawData(homoGcnData)\n",
        "  plotLoss(loss_values)\n",
        "\n",
        "  return pred, ground_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgkH34eHj-JQ"
      },
      "source": [
        "### GAT Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QS6s_4Vkjg5w"
      },
      "outputs": [],
      "source": [
        "def GatModel():\n",
        "  GATModule = GAT(embedding_size, hidden_size, out_size, layers=layers, device=device)\n",
        "  gatData = []\n",
        "\n",
        "  optimizer = torch.optim.Adam(GATModule.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = total_examples = 0\n",
        "    GATModule.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = GATModule(hetero_train_data)\n",
        "    ground_truth = hetero_train_data['team_in_match', 'result', 'team_in_match'].edge_attr\n",
        "    loss = crit(pred, ground_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validate\n",
        "    GATModule.eval()\n",
        "    pred = GATModule(hetero_val_data).to(device)\n",
        "    ground_truth = hetero_val_data[\"team_in_match\", \"result\", \"team_in_match\"].edge_attr.to(device)\n",
        "\n",
        "    gatMetric = Metrics(device)\n",
        "    gatMetric.update(pred.T, ground_truth.T)\n",
        "    compute = gatMetric.compute()\n",
        "    gatData.append(compute)\n",
        "\n",
        "  for key in compute:\n",
        "    print(f\"{key}: {compute[key]}\")\n",
        "\n",
        "  drawData(gatData)\n",
        "\n",
        "  return pred, ground_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQgTcbqmd7Y4"
      },
      "source": [
        "### Homogen GAT Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Hr3M2o3veBFB"
      },
      "outputs": [],
      "source": [
        "def HomogenGatModel():\n",
        "  homoGATModule = homoGAT(embedding_size, hidden_size, out_size, layers=layers, device=device)\n",
        "  homoGatData = []\n",
        "\n",
        "  optimizer = torch.optim.Adam(homoGATModule.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = total_examples = 0\n",
        "    homoGATModule.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    pred = homoGATModule(homo_train_data).to(device)\n",
        "    ground_truth = homo_train_data.edge_attr.to(device)\n",
        "    loss = crit(pred, ground_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validate\n",
        "    homoGATModule.eval()\n",
        "    pred = homoGATModule(homo_val_data).to(device)\n",
        "    ground_truth = homo_val_data.edge_attr.to(device)\n",
        "\n",
        "    homoGatMetric = Metrics(device)\n",
        "    homoGatMetric.update(pred.T, ground_truth.T)\n",
        "    compute = homoGatMetric.compute()\n",
        "    homoGatData.append(compute)\n",
        "\n",
        "  for key in compute:\n",
        "    print(f\"{key}: {compute[key]}\")\n",
        "\n",
        "  drawData(homoGatData)\n",
        "\n",
        "  return pred, ground_truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1nbDFItfvHP"
      },
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred, ground = HomogenGcnModel()\n",
        "\n",
        "printResults(pred)\n",
        "printResults(ground)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "VOhUeOiV7bLJ",
        "outputId": "7a588bc0-6f7e-456c-b96a-d43dded0f57f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0.8563  -0.8891   0.4708  -0.4161   0.8563  -0.8891   0.4708  -0.4161   0.8563  -0.8891   0.4708  -0.4161 \n",
            "  1.0000  -1.0000   1.0000  -1.0000   1.0000  -1.0000   1.0000  -1.0000   1.0000  -1.0000   1.0000  -1.0000 \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VBFEUPjNChfb",
        "Z_bTeA4IClUF",
        "zCsW9wIPMGhm",
        "xRyuNWZAFELV",
        "utTRzV2s254U",
        "eN83x5Kyt_-s",
        "DIb_W7__9gwk",
        "dfTaSYJuyRhW",
        "g0mMc5H924yA",
        "aB9prObutrWq",
        "rQFhdJpZxlIV",
        "d5-mQqCuzGF9",
        "WbAue-pAHJ96",
        "uY6Ui5v-Cy27",
        "XLhx7YnwvJ_4",
        "FW0eaun_bRHk",
        "ahKxTgQKF7Xv",
        "sXjdRfifF4mP",
        "ydDxJlvA53dw",
        "E1UuxaWEbpbk",
        "C0-Hkkxv-9ih",
        "FBU2khASw9fc",
        "VzviYSH_pGYW",
        "31UbMviCdi0R",
        "9V7c55wGdn66",
        "IjGwyEOAnulm",
        "YgpRrXXy6Bt_",
        "nXWygaeMj5Xu",
        "lnII2YqMdQ9c",
        "sCjc3rNjj8V6",
        "qrdvl6lVyoFb",
        "xgkH34eHj-JQ",
        "pQgTcbqmd7Y4"
      ],
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOas46ats9YR91ojLvuXY4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}