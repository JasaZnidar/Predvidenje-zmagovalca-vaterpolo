{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasaZnidar/Predvidenje-zmagovalca-vaterpolo/blob/mathematics-all3/Diplomska_naloga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBFEUPjNChfb"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "pQMPL8B7EWKB"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import json\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import random\n",
        "from math import sqrt, pow, isnan\n",
        "from typing import Callable\n",
        "from sys import float_info\n",
        "from functools import lru_cache\n",
        "import copy\n",
        "from statistics import mean\n",
        "\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ePQ7qQm9Nj4"
      },
      "source": [
        "# Support functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "7096-S8H9QDv"
      },
      "outputs": [],
      "source": [
        "# @title Event data to vector data\n",
        "def eventToVector(event: dict) -> tuple[list[float], list[float]]:\n",
        "  player1Statistic = [0.0]*11\n",
        "  player2Statistic = [0.0]*11\n",
        "\n",
        "  if \"goal scored\" in event['action']:\n",
        "    # goals\n",
        "    player1Statistic[0] += 1\n",
        "    # shots\n",
        "    player1Statistic[1] += 1\n",
        "    # assists\n",
        "    player2Statistic[2] += 1\n",
        "\n",
        "  elif \"exclusion\" in event['action']:\n",
        "    # exclusion\n",
        "    player1Statistic[5] += 1\n",
        "\n",
        "  elif \"penalty foul\" in event['action']:\n",
        "    # penalty\n",
        "    player1Statistic[6] += 1\n",
        "\n",
        "  elif \"shot missed\" in event['action']:\n",
        "    # shots\n",
        "    player1Statistic[1] += 1\n",
        "\n",
        "  elif \"shot saved\" in event['action']:\n",
        "    # shots\n",
        "    player1Statistic[1] += 1\n",
        "\n",
        "  elif \"shot blocked\" in event['action']:\n",
        "    # shots\n",
        "    player1Statistic[1] += 1\n",
        "    # blocks\n",
        "    player2Statistic[3] += 1\n",
        "\n",
        "  elif \"suspention\" in event['action']:\n",
        "    # suspensions\n",
        "    player1Statistic[7] += 1\n",
        "\n",
        "  elif \"brutality\" in event['action']:\n",
        "    # brutalities\n",
        "    player1Statistic[8] += 1\n",
        "\n",
        "  elif \"sprint won\" in event['action']:\n",
        "    # sprint won\n",
        "    player1Statistic[9] += 1\n",
        "    # sprint\n",
        "    player1Statistic[10] += 1\n",
        "    # sprint\n",
        "    player2Statistic[10] += 1\n",
        "\n",
        "  return (player1Statistic, player2Statistic);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "kisIBpzq9W9A"
      },
      "outputs": [],
      "source": [
        "# @title Is second player ally\n",
        "def isAlly(event: dict) -> bool:\n",
        "  if 'goal scored' in event['action']:\n",
        "    return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "gYvS_0SG9fU5"
      },
      "outputs": [],
      "source": [
        "# @title Update list\n",
        "def Update(original: list, update: list) -> list:\n",
        "  assert len(original) == len(update)\n",
        "\n",
        "  return[original[x] + update[x] for x in range(len(original))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "-RB3V5kx1n1a"
      },
      "outputs": [],
      "source": [
        "# @title Resize array by mask\n",
        "def resizeByMask(array: np.array, mask: list):\n",
        "  retArray = []\n",
        "  for i in range(len(mask)):\n",
        "    if mask[i]:\n",
        "      retArray.append(array[i])\n",
        "\n",
        "  return np.array(retArray)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "cF3x4yr_N1Qs"
      },
      "outputs": [],
      "source": [
        "# @title Classification\n",
        "def classify(val: float, allowTie: bool = True):\n",
        "  if allowTie:\n",
        "    if val >= 0.5:\n",
        "      return 1\n",
        "    elif val <= -0.5:\n",
        "      return -1\n",
        "    return 0\n",
        "  else:\n",
        "    if val >= 0:\n",
        "      return 1\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "baFZlbU5Wjy9"
      },
      "outputs": [],
      "source": [
        "# @title Team data normalization\n",
        "def normTeamData(data: list[list[float], float]):\n",
        "  if data[1] == 0:\n",
        "    return [0.0]*num_playerInMatch_features\n",
        "  return np.array(data[0])/data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "CDD6LGJjYNVH"
      },
      "outputs": [],
      "source": [
        "# @title Clustering functions\n",
        "def manhattan_dist(r1: np.array, r2: np.array) -> float:\n",
        "  return np.nanmean(abs(r1 - r2))\n",
        "\n",
        "def euclidean_dist(r1: np.array, r2: np.array) -> float:\n",
        "  return sqrt(np.nanmean((r1 - r2)**2))\n",
        "\n",
        "def single_linkage(c1: list, c2: list, distance_fn: Callable) -> float:\n",
        "  dist = np.array([distance_fn(p1, p2) for p2 in c2 for p1 in c1])\n",
        "  return np.nanmin(dist)\n",
        "\n",
        "\n",
        "def complete_linkage(c1: list, c2: list, distance_fn: Callable) -> float:\n",
        "  dist = np.array([distance_fn(p1, p2) for p2 in c2 for p1 in c1])\n",
        "  return np.nanmax(dist)\n",
        "\n",
        "\n",
        "def average_linkage(c1: list, c2: list, distance_fn: Callable) -> float:\n",
        "  dist = np.array([distance_fn(p1, p2) for p2 in c2 for p1 in c1])\n",
        "  return np.nanmean(dist)\n",
        "\n",
        "\n",
        "def singleDim(l: list) -> list:\n",
        "  # are there multiple layers\n",
        "  if type(l) == list:\n",
        "    ret = []\n",
        "    for l_i in l:\n",
        "      ret += singleDim(l_i)\n",
        "\n",
        "    return ret\n",
        "\n",
        "  # the list can't be broken down further\n",
        "  else:\n",
        "    if type(l) == str:\n",
        "      return [l]\n",
        "\n",
        "    # value is distance\n",
        "    return []\n",
        "\n",
        "\n",
        "def silhouette(el: str, clusters: list, data: dict) -> float:\n",
        "  distance = euclidean_dist\n",
        "\n",
        "  # locate local cluster\n",
        "  for I in range(len(clusters)):\n",
        "    cluster_I = singleDim(clusters[I])\n",
        "    if el in cluster_I:\n",
        "      a_el = 0\n",
        "\n",
        "      if len(cluster_I) == 1:\n",
        "        return 0.0\n",
        "\n",
        "      for c in cluster_I:\n",
        "        a_el += distance(data[el], data[c])\n",
        "      a_el /= len(cluster_I) - 1\n",
        "\n",
        "      b_el = float_info.max\n",
        "      for J in range(len(clusters)):\n",
        "        if J == I:\n",
        "          continue\n",
        "\n",
        "        b_new = 0\n",
        "        cluster_J = singleDim(clusters[J])\n",
        "        for c in cluster_J:\n",
        "          b_new += distance(data[el], data[c])\n",
        "        b_new /= len(cluster_J)\n",
        "\n",
        "        b_el = min(b_el, b_new)\n",
        "\n",
        "      s_el = (b_el - a_el)/max(a_el, b_el)\n",
        "      return s_el\n",
        "\n",
        "\n",
        "def silhouette_average(data: dict, clusters: list) -> float:\n",
        "  cluster = singleDim(clusters)\n",
        "  ret = 0\n",
        "  for el in cluster:\n",
        "    ret += silhouette(el, clusters, data)\n",
        "  ret /= len(cluster)\n",
        "\n",
        "  return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kopdDEI_uq9"
      },
      "source": [
        "# Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "k7WoWjMJFGVT"
      },
      "outputs": [],
      "source": [
        "# @title Data settings\n",
        "data_file = \"test\"\n",
        "train_rate = 0.7\n",
        "val_rate = 1.0 - train_rate\n",
        "\n",
        "# goals, shots, assists, blocks, saves, exclusion, penalty foul, suspention, brutality, sprint won, sprints\n",
        "used_features = [1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]#[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]#\n",
        "num_playerInMatch_features = sum(used_features)\n",
        "# birth, hand height, position, weight\n",
        "used_player_stats = [1, 1, 1, 1, 1]\n",
        "num_player_features = sum(used_player_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "yAffGkJiJLXe"
      },
      "outputs": [],
      "source": [
        "# @title Get JSON data from github\n",
        "with requests.get(f\"https://github.com/JasaZnidar/totalwaterpolo-web-scraper/raw/master/{data_file}.zip\", ) as r:\n",
        "  ZipFile(BytesIO(r.content), \"r\").extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "id": "IVWhen3IJrf7"
      },
      "outputs": [],
      "source": [
        "# @title Extract data to json object\n",
        "with open(f\"/content/{data_file}.json\") as f:\n",
        "    scraped_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "rGuwcj6c81V4"
      },
      "outputs": [],
      "source": [
        "# @title Team and Match data\n",
        "def getData(matches: dict[str, dict], stop: int = None, skipTie: bool = False):\n",
        "  match_list = [match_id for match_id in matches]\n",
        "  if stop is not None:\n",
        "    match_list = match_list[:stop]\n",
        "\n",
        "  match_data = {}\n",
        "  team_data = {}\n",
        "\n",
        "  for match_id in match_list:\n",
        "    #=============================================================================\n",
        "    # Collect match data\n",
        "    #=============================================================================\n",
        "    match_data[match_id] = [\n",
        "        matches[match_id]['result']['away'] - matches[match_id]['result']['home'],\n",
        "        matches[match_id]['name']['home'],\n",
        "        matches[match_id]['name']['away'],\n",
        "        [],\n",
        "        []\n",
        "    ]\n",
        "\n",
        "    #=============================================================================\n",
        "    # Check if ties are skipped\n",
        "    #=============================================================================\n",
        "    if skipTie and match_data[match_id][0] == 0:\n",
        "      del match_data[match_id]\n",
        "      continue\n",
        "\n",
        "    #=============================================================================\n",
        "    # Prepare statistics dictionary for a teams players\n",
        "    #=============================================================================\n",
        "    statistics = {\n",
        "        'home': {int(x): [0.0]*num_playerInMatch_features for x in matches[match_id]['lineup']['home']},\n",
        "        'away': {int(x): [0.0]*num_playerInMatch_features for x in matches[match_id]['lineup']['away']}\n",
        "    }\n",
        "\n",
        "    if len(statistics['home']) < 7 or len(statistics['away']) < 7:\n",
        "      del match_data[match_id]\n",
        "      continue\n",
        "\n",
        "    #=============================================================================\n",
        "    # Add missing teams in team_data\n",
        "    #=============================================================================\n",
        "    for team in ['home', 'away']:\n",
        "      if not matches[match_id]['name'][team] in team_data:\n",
        "        team_data[matches[match_id]['name'][team]] = [[0.0]*num_playerInMatch_features, 0]\n",
        "\n",
        "    #=============================================================================\n",
        "    # Loop through all events and update player statistics\n",
        "    #=============================================================================\n",
        "    for event in matches[match_id]['plays']:\n",
        "      num_1 = event['player_1']\n",
        "      num_2 = event['player_2']\n",
        "      primary_team = event['team']\n",
        "      secondary_team = primary_team if isAlly(event) else 'away' if primary_team == 'home' else 'home'\n",
        "\n",
        "      # no player was recorded for this event\n",
        "      if num_1 == 0:\n",
        "        continue\n",
        "\n",
        "      # no secondary player was recorded for this event\n",
        "      elif num_2 == 0:\n",
        "        data_1, _ = eventToVector(event)\n",
        "        statistics[primary_team][num_1] = Update(statistics[primary_team][num_1], resizeByMask(data_1, used_features))\n",
        "\n",
        "      # there are 2 players recorded for this event\n",
        "      else:\n",
        "        data_1, data_2 = eventToVector(event)\n",
        "        statistics[primary_team][num_1] = Update(statistics[primary_team][num_1], resizeByMask(data_1, used_features))\n",
        "        statistics[secondary_team][num_2] = Update(statistics[secondary_team][num_2], resizeByMask(data_2, used_features))\n",
        "\n",
        "    #=============================================================================\n",
        "    # Update match data\n",
        "    #=============================================================================\n",
        "    match_data[match_id][3] = team_data[matches[match_id]['name']['home']].copy()\n",
        "    match_data[match_id][4] = team_data[matches[match_id]['name']['away']].copy()\n",
        "\n",
        "    #=============================================================================\n",
        "    # Update team overall data\n",
        "    #=============================================================================\n",
        "    for team in ['home', 'away']:\n",
        "      team_name = matches[match_id]['name'][team]\n",
        "\n",
        "      for player in statistics[team]:\n",
        "        team_data[team_name][0] = Update(team_data[team_name][0], statistics[team][player])\n",
        "        team_data[team_name][1] += 1\n",
        "\n",
        "  return (match_data, team_data)\n",
        "\n",
        "match_data, team_data = getData(scraped_data['matches'])\n",
        "noTieMatch_data, noTieTeam_data = getData(scraped_data['matches'], skipTie=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08F2CIEs8GGN"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "nGuv8Yhq2Vam"
      },
      "outputs": [],
      "source": [
        "# @title Statistics\n",
        "class Statistics:\n",
        "  def __init__(self, match_data: dict[str, list[int, str, str, list[float], list[float]]]):\n",
        "    self.match_data = match_data\n",
        "    self.resultStats = [0, 0, 0] # from home perspective: [win, tie, loss]\n",
        "\n",
        "    for match_id in scraped_data['matches']:\n",
        "      lineup = scraped_data['matches'][match_id]['lineup']\n",
        "      if len(lineup['home']) < 7 or len(lineup['away']) < 7:\n",
        "        continue\n",
        "\n",
        "      diff = scraped_data['matches'][match_id]['result']['home'] - scraped_data['matches'][match_id]['result']['away']\n",
        "      if diff > 0:\n",
        "        self.resultStats[0] += 1\n",
        "      elif diff < 0:\n",
        "        self.resultStats[2] += 1\n",
        "      else:\n",
        "        self.resultStats[1] += 1\n",
        "\n",
        "  def Predict(self):\n",
        "    stats = [\n",
        "        self.resultStats[0] / sum(self.resultStats),\n",
        "        self.resultStats[1] / sum(self.resultStats),\n",
        "        self.resultStats[2] / sum(self.resultStats)\n",
        "    ]\n",
        "    values = [1, 0, -1]\n",
        "\n",
        "    return values[np.argmax(stats)]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title k-mean Clustering\n",
        "class kMeanCluster:\n",
        "  def __init__(self, k: int, match_data: dict[str, list]):\n",
        "    assert k > 1\n",
        "\n",
        "    self.centroids = np.zeros((k, 2*num_playerInMatch_features))\n",
        "    match_vectors = {match_id: np.concatenate((normTeamData(match_data[match_id][3]), normTeamData(match_data[match_id][4]))) for match_id in match_data.keys()}\n",
        "\n",
        "    # select select starting points as clusters (first one will be close to zero and the others as far appart from each other as possible)\n",
        "    match_list = list(match_data.keys())\n",
        "    clusters = []\n",
        "    init_cluster = []\n",
        "\n",
        "    # first point\n",
        "    dist_0 = [np.sum(np.abs(match_vectors[match_list[n]])) for n in range(len(match_list))]\n",
        "    n = np.argmin(dist_0)\n",
        "    self.centroids[0, :] = match_vectors[match_list[n]]\n",
        "    clusters.append([match_list[n]])\n",
        "    init_cluster.append(n)\n",
        "\n",
        "    for i in range(1, k):\n",
        "      # distances from already chosen points\n",
        "      dist = [0.0 if n in init_cluster else mean([np.sum(np.abs(match_vectors[match_list[m]] - match_vectors[match_list[n]])) for m in init_cluster]) for n in range(len(match_list))]\n",
        "\n",
        "      n = np.argmax(dist)\n",
        "      self.centroids[i, :] = match_vectors[match_list[n]]\n",
        "      clusters.append([match_list[n]])\n",
        "      init_cluster.append(n)\n",
        "\n",
        "    # split into clusters\n",
        "    #print(clusters)\n",
        "    for i in range(len(match_list)):\n",
        "      if i in init_cluster:\n",
        "        continue\n",
        "      match_vector = match_vectors[match_list[i]]\n",
        "      dist = self.distance(match_vector)\n",
        "      closest = np.argmin(dist)\n",
        "\n",
        "      clusters[closest].append(match_list[i])\n",
        "\n",
        "    #self.ClusterSize(clusters)\n",
        "\n",
        "    # update clusters until they are no longer updated\n",
        "    change = True\n",
        "    while change:\n",
        "      # update centroids\n",
        "      for i in range(k):\n",
        "        self.centroids[i, :] = np.mean(np.array([match_vectors[match_id] for match_id in clusters[i]]), axis=0)\n",
        "\n",
        "      # calculate new clusers\n",
        "      new_clusters = [[] for _ in range(k)]\n",
        "      for i in range(len(match_list)):\n",
        "        match_vector = match_vectors[match_list[i]]\n",
        "        dist = self.distance(match_vector)\n",
        "        closest = np.argmin(dist)\n",
        "\n",
        "        new_clusters[closest].append(match_list[i])\n",
        "\n",
        "      # compare old and new clusters\n",
        "      change = False\n",
        "      for i in range(k):\n",
        "        if not len(clusters[i]) == len(new_clusters[i]):\n",
        "          #print(f\"Size in new cluster {i+1} is {len(new_clusters[i])} instead of {len(clusters[i])}.\")\n",
        "          change = True\n",
        "          break\n",
        "        for j in range(len(clusters[i])):\n",
        "          if clusters[i][j] not in new_clusters[i]:\n",
        "            #print(f\"Match {clusters[i][j]} was not found in new cluster, was moved.\")\n",
        "            change = True\n",
        "            break\n",
        "\n",
        "      clusters = new_clusters\n",
        "      #self.ClusterSize(clusters)\n",
        "\n",
        "    # calculate centroid values\n",
        "    self.centroid_values = [mean([match_data[match_id][0] for match_id in cluster]) for cluster in clusters]\n",
        "    #print(self.centroid_values)\n",
        "\n",
        "  def distance(self, vector):\n",
        "    return [np.sum(np.abs(self.centroids[i, :] - vector)) for i in range(self.centroids.shape[0])]\n",
        "\n",
        "  def ClusterSize(self, clusters):\n",
        "    print(f\"[\", end=\"\")\n",
        "    for i in range(len(clusters)):\n",
        "      print(f\"{len(clusters[i])}\", end=\"\")\n",
        "      if i != len(clusters) - 1:\n",
        "        print(f\", \", end=\"\")\n",
        "    print(f\"]\")\n",
        "\n",
        "    return\n",
        "\n",
        "  def Predict(self, home_team: str, away_team: str, team_data: dict[str, list[float]]):\n",
        "    if home_team not in team_data:\n",
        "      home = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      home = normTeamData(team_data[home_team])\n",
        "\n",
        "    if away_team not in team_data:\n",
        "      away = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      away = normTeamData(team_data[away_team])\n",
        "\n",
        "    match_vector = np.concatenate((home, away))\n",
        "\n",
        "    dist = self.distance(match_vector)\n",
        "    closest = np.argmin(dist)\n",
        "\n",
        "    return self.centroid_values[closest]"
      ],
      "metadata": {
        "id": "Z_pwAsox7TFL",
        "cellView": "form"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "3Uj0fvujYDZD"
      },
      "outputs": [],
      "source": [
        "# @title Hierarchical clustering\n",
        "class HierarchicalClustering:\n",
        "  def __init__(self, link_function: Callable, dist_function: Callable, match_data: dict[str, list], max_dist: float = 0.3):\n",
        "    self.dist = dist_function\n",
        "    self.link = link_function\n",
        "    self.return_distances = True\n",
        "    self.match_results = {match_id: match_data[match_id][0] for match_id in match_data.keys()}\n",
        "\n",
        "    self.data = {}\n",
        "    self.results = {}\n",
        "    for match_id in match_data:\n",
        "      home = normTeamData(match_data[match_id][3])\n",
        "      away = normTeamData(match_data[match_id][4])\n",
        "      self.data[match_id] = np.concatenate((home, away))\n",
        "      self.results[match_id] = match_data[match_id][0]\n",
        "\n",
        "    clusters = [[name] for name in self.data.keys()]\n",
        "    self.clusterStrings = [name for name in self.data.keys()]\n",
        "    distance = 0.0\n",
        "\n",
        "    # create clusters\n",
        "    while len(clusters) >= 2:\n",
        "      print(f\"\\r{len(clusters)} - {distance:.4}\", end=\"\")\n",
        "      first, second, distance = self.closest_clusters(clusters)\n",
        "\n",
        "      # check if dist is too large\n",
        "      if distance > max_dist:\n",
        "        break\n",
        "\n",
        "      # update the \"clusters\" variable\n",
        "      c1_i = clusters.index(first)\n",
        "      c2_i = clusters.index(second)\n",
        "\n",
        "      # c1_i < c2_i\n",
        "      del clusters[c2_i]\n",
        "      if self.return_distances:\n",
        "        clusters[c1_i] = [first, second, distance]\n",
        "      else:\n",
        "        clusters[c1_i] = [first, second]\n",
        "      self.clusterStrings[c1_i] += \",\" + self.clusterStrings[c2_i]\n",
        "      del self.clusterStrings[c2_i]\n",
        "\n",
        "    self.clusters = clusters\n",
        "\n",
        "    # classify clusters\n",
        "    self.classification = [float(np.mean(np.array([self.match_results[match_id] for match_id in clusterString.split(\",\")]))) for clusterString in self.clusterStrings]\n",
        "\n",
        "  @lru_cache(maxsize=None)\n",
        "  def dist_cache(self, match1: str, match2: str) -> float:\n",
        "    c1 = self.data[match1]\n",
        "    c2 = self.data[match2]\n",
        "\n",
        "    return self.dist(c1, c2)\n",
        "\n",
        "  @lru_cache(maxsize=None)\n",
        "  def link_cache(self, cluster1: str, cluster2: str):\n",
        "    matches1 = cluster1.split(\",\")\n",
        "    matches2 = cluster2.split(\",\")\n",
        "\n",
        "    return self.link(matches1, matches2, self.dist_cache)\n",
        "\n",
        "  def closest_clusters(self, clusters: list) -> tuple[list[str], list[str], float]:\n",
        "    # starting clusters\n",
        "    c1 = clusters[0]\n",
        "    c2 = clusters[1]\n",
        "\n",
        "    # first distance and length\n",
        "    dist = self.link_cache(self.clusterStrings[0], self.clusterStrings[1])\n",
        "    C = len(clusters)\n",
        "\n",
        "    for i in range(C):\n",
        "      for j in range(i+1, C):\n",
        "        new_dist = self.link_cache(self.clusterStrings[i], self.clusterStrings[j])\n",
        "        if isnan(new_dist):\n",
        "          continue\n",
        "\n",
        "        if isnan(dist) or new_dist < dist:\n",
        "          dist = new_dist\n",
        "          c1 = clusters[i]\n",
        "          c2 = clusters[j]\n",
        "\n",
        "    return (c1, c2, dist)\n",
        "\n",
        "  def Predict(self, home_team: str, away_team: str, team_data: dict[str, list[float]]):\n",
        "    if home_team not in team_data:\n",
        "      home = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      home = normTeamData(team_data[home_team])\n",
        "\n",
        "    if away_team not in team_data:\n",
        "      away = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      away = normTeamData(team_data[away_team])\n",
        "\n",
        "\n",
        "    match_data = np.concatenate((home, away))\n",
        "\n",
        "    # calculate distance\n",
        "    links = np.array([self.link([match_data], [self.data[match_id] for match_id in clusterStr.split(\",\")], self.dist) for clusterStr in self.clusterStrings])\n",
        "\n",
        "    # get prediction value\n",
        "    closestCluster = np.argmin(links)\n",
        "    return self.classification[closestCluster]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WqzrRein8xdX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title KNN\n",
        "class KNN:\n",
        "  def __init__(self, k: int, team_data: dict[str, list[list[float], int]], match_history: dict[str, list[int, str, str, list[float], list[float]]]):\n",
        "    self.k = k\n",
        "\n",
        "    teams = list(team_data.keys())\n",
        "    self.team_data = {\n",
        "        team: normTeamData(team_data[team])\n",
        "        for team in team_data\n",
        "    }\n",
        "    self.match_history = match_history\n",
        "\n",
        "  def Predict(self, friendly_team: str, enemy_team: str, friendly_home: bool = None) -> float:\n",
        "    if friendly_team not in self.team_data and enemy_team not in self.team_data:\n",
        "      # both teams are unknown, return tie\n",
        "      return 0\n",
        "\n",
        "    if enemy_team not in self.team_data:\n",
        "      # enemy team has no history, reverse the question and then the answer\n",
        "      return -self.Predict(enemy_team, friendly_team, not friendly_home)\n",
        "\n",
        "    # collect all teams who played against the enemy team\n",
        "    neighbors = set([])\n",
        "    neighbor_results = {}\n",
        "    for match_id in self.match_history:\n",
        "      history_match = self.match_history[match_id]\n",
        "\n",
        "      # friendly team is not home team => enemy team is home\n",
        "      if friendly_home != True and history_match[1] == enemy_team:\n",
        "        neighbors.add(history_match[2])\n",
        "        if history_match[2] not in neighbor_results:\n",
        "          neighbor_results[history_match[2]] = []\n",
        "        neighbor_results[history_match[2]].append(history_match[0])\n",
        "\n",
        "      # friendly team is not away team => enemy team is away\n",
        "      if friendly_home != False and history_match[2] == enemy_team:\n",
        "        neighbors.add(history_match[1])\n",
        "        if history_match[1] not in neighbor_results:\n",
        "          neighbor_results[history_match[1]] = []\n",
        "        neighbor_results[history_match[1]].append(history_match[0])\n",
        "\n",
        "    # form a neighbor matrix for distnce\n",
        "    neighbor_matrix = np.zeros((len(neighbors), num_playerInMatch_features))\n",
        "    neighbor_index = []\n",
        "    for neighbor in neighbors:\n",
        "      neighbor_matrix[len(neighbor_index), :] = self.team_data[neighbor]\n",
        "      neighbor_index.append(neighbor)\n",
        "\n",
        "    # calculate distance\n",
        "    if friendly_team not in self.team_data:\n",
        "      neighbor_distance = (neighbor_matrix)**2\n",
        "    else:\n",
        "      neighbor_distance = (neighbor_matrix - self.team_data[friendly_team])**2\n",
        "    neighbor_distance = np.nansum(neighbor_distance, axis=1)\n",
        "\n",
        "    # select k nearest neighbors, if possible\n",
        "    modifier = 1\n",
        "    if len(neighbor_distance) < self.k:\n",
        "      knn_index = [n for n in range(len(neighbor_distance))]\n",
        "      modifier = len(neighbor_distance)/self.k  # normalize data to match uncertanty\n",
        "      if len(neighbor_distance) == 0:\n",
        "        # enemy team has no history, reverse the question and then the answer\n",
        "        return 0\n",
        "      #warnings.warn(\"Not enough neighbors to make a full prediction. Prediction will be made with {} neighbors instead of {}.\".format(len(neighbor_distance), self.k))\n",
        "    elif len(neighbor_distance) == self.k:\n",
        "      knn_index = [n for n in range(len(neighbor_distance))]\n",
        "    else:\n",
        "      knn_index = np.argpartition(neighbor_distance, self.k)[:self.k]\n",
        "\n",
        "    # calculate prediction\n",
        "    pred = 0.0\n",
        "    weight = 0.0\n",
        "    for i in knn_index:\n",
        "      for result in neighbor_results[neighbor_index[i]]:\n",
        "        pred += result * (1/(neighbor_distance[i] + 1))\n",
        "        weight += 1/(neighbor_distance[i] + 1)\n",
        "    pred /= weight\n",
        "\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "XgYlaTdOUbME"
      },
      "outputs": [],
      "source": [
        "# @title Linear regresion\n",
        "def gradient(X: np.ndarray, y: np.ndarray, theta: np.ndarray, l2_lambda: float) -> np.array:\n",
        "    _, m = X.shape\n",
        "    L2 = np.ones((m,)) * l2_lambda\n",
        "    L2[0] = 0.0\n",
        "\n",
        "    return np.dot(np.dot(X, theta) - y, X) + L2*theta\n",
        "\n",
        "\n",
        "def gradient_descent(X: np.ndarray, y: np.ndarray, l2_lambda: float, lr=0.01, tol=1e-6, max_iter=100_000) -> np.array:\n",
        "    _, m = X.shape\n",
        "    theta = np.ones((m, ))\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        theta_next = theta - lr*gradient(X, y, theta, l2_lambda)\n",
        "\n",
        "        if np.isinf(theta_next).any() or np.isnan(theta_next).any():\n",
        "            return theta\n",
        "\n",
        "        diff = np.linalg.norm(gradient(X, y, theta_next, l2_lambda))\n",
        "        if np.isinf(diff):\n",
        "          raise Exception(\"Diff is inf.\")\n",
        "        if np.isnan(diff):\n",
        "          raise Exception(\"Diff is nan.\")\n",
        "\n",
        "        if diff < tol:\n",
        "            return theta_next\n",
        "\n",
        "        theta = theta_next\n",
        "\n",
        "    return theta\n",
        "\n",
        "class LinReg:\n",
        "  def __init__(self, match_history: dict[str, list[int, str, str, list[float], list[float]]]):\n",
        "    # prepare learning data\n",
        "    X = np.zeros((len(match_history), 2*num_playerInMatch_features))\n",
        "    y = np.zeros((len(match_history)))\n",
        "\n",
        "    # fill out learning data\n",
        "    match_list = list(match_history.keys())\n",
        "    for i in range(len(match_list)):\n",
        "      match_id = match_list[i]\n",
        "      home_data = normTeamData(match_history[match_id][3])\n",
        "      away_data = normTeamData(match_history[match_id][4])\n",
        "\n",
        "      X[i, :] = np.concatenate((home_data, away_data))\n",
        "      y[i] = match_history[match_id][0] # result\n",
        "\n",
        "    # add coeficient to X\n",
        "    X_ = np.concatenate((np.ones((len(match_history), 1)), X), axis=1)\n",
        "\n",
        "    # gradient descent\n",
        "    theta = gradient_descent(X_, y, 0.0, 1e-5, 1e-8, 1_000_000)\n",
        "\n",
        "    self.coefs = theta[1:]\n",
        "    self.intercept = theta[0]\n",
        "\n",
        "  def Predict(self, home_team: str, away_team: str, team_data: dict[str, list[float]]):\n",
        "    if home_team not in team_data or away_team not in team_data:\n",
        "      home = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      home = np.array(team_data[home_team][0])/team_data[home_team][1]\n",
        "\n",
        "    if away_team not in team_data:\n",
        "      away = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      away = np.array(team_data[away_team][0])/team_data[away_team][1]\n",
        "\n",
        "    home = np.reshape(home, (1, -1))\n",
        "    away = np.reshape(away, (1, -1))\n",
        "\n",
        "    X_ = np.concatenate((np.ones((1, 1)), home, away), axis=1)\n",
        "    theta = np.insert(self.coefs, 0, self.intercept)\n",
        "\n",
        "    return np.dot(X_, theta)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "id": "Dc2FvLQ1HZiA"
      },
      "outputs": [],
      "source": [
        "# @title Logistic regression\n",
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def logGradient(X: np.ndarray, y: np.ndarray, theta: np.ndarray, l2_lambda: float) -> np.array:\n",
        "    _, m = X.shape\n",
        "    L2 = np.ones((m,)) * l2_lambda\n",
        "\n",
        "    return np.dot(sigmoid(np.dot(X, theta)) - y, X) + L2*theta\n",
        "\n",
        "\n",
        "def logGradient_descent(X: np.ndarray, y: np.ndarray, l2_lambda: float, lr=0.01, tol=1e-6, max_iter=100_000) -> np.array:\n",
        "    _, m = X.shape\n",
        "    theta = np.ones((m, ))\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "      theta_next = theta - lr*logGradient(X, y, theta, l2_lambda)\n",
        "\n",
        "      if np.isinf(theta_next).any() or np.isnan(theta_next).any():\n",
        "          return theta\n",
        "\n",
        "      diff = np.linalg.norm(logGradient(X, y, theta_next, l2_lambda))\n",
        "      if np.isinf(diff):\n",
        "        raise Exception(\"Diff is inf.\")\n",
        "      if np.isnan(diff):\n",
        "        raise Exception(\"Diff is nan.\")\n",
        "\n",
        "      if diff < tol:\n",
        "          return theta_next\n",
        "\n",
        "      theta = theta_next\n",
        "\n",
        "    return theta\n",
        "\n",
        "class LogReg:\n",
        "  def __init__(self, match_history: dict[str, list[int, str, str, list[float], list[float]]]):\n",
        "    # prepare learning data\n",
        "    X = np.zeros((len(match_history), 2*num_playerInMatch_features))\n",
        "    y = np.zeros((len(match_history)))\n",
        "\n",
        "    # fill out learning data\n",
        "    match_list = list(match_history.keys())\n",
        "    for i in range(len(match_list)):\n",
        "      match_id = match_list[i]\n",
        "      home_data = normTeamData(match_history[match_id][3])\n",
        "      away_data = normTeamData(match_history[match_id][4])\n",
        "      if np.isnan(home_data).any() or np.isnan(away_data).any():\n",
        "        print(match_id)\n",
        "        print(match_history[match_id])\n",
        "\n",
        "      X[i, :] = np.concatenate((home_data, away_data))\n",
        "      y[i] = match_history[match_id][0] # result\n",
        "\n",
        "    # prepare logistic y\n",
        "    yWin = y >= 0.5;\n",
        "    yLoss = y <= -0.5;\n",
        "    yTie  = np.logical_not(np.logical_or(yWin, yLoss))\n",
        "\n",
        "    # gradient descent\n",
        "    L2 = 0.0\n",
        "    lr = 1e-5\n",
        "    tol = 1e-8\n",
        "    max_iter = 1_000_000\n",
        "    self.thetaWin = logGradient_descent(X, yWin, L2, lr, tol, max_iter)\n",
        "    self.thetaTie = logGradient_descent(X, yTie, L2, lr, tol, max_iter)\n",
        "    self.thetaLoss = logGradient_descent(X, yLoss, L2, lr, tol, max_iter)\n",
        "\n",
        "  def Predict(self, home_team: str, away_team: str, team_data: dict[str, list[float]]):\n",
        "    if home_team not in team_data or away_team not in team_data:\n",
        "      home = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      home = np.array(team_data[home_team][0])/team_data[home_team][1]\n",
        "\n",
        "    if away_team not in team_data:\n",
        "      away = np.zeros((num_playerInMatch_features,))\n",
        "    else:\n",
        "      away = np.array(team_data[away_team][0])/team_data[away_team][1]\n",
        "\n",
        "    home = np.reshape(home, (1, -1))\n",
        "    away = np.reshape(away, (1, -1))\n",
        "\n",
        "    X_ = np.concatenate((home, away), axis=1)\n",
        "\n",
        "    win = sigmoid(np.dot(X_, self.thetaWin))[0]\n",
        "    tie = sigmoid(np.dot(X_, self.thetaTie))[0]\n",
        "    loss = sigmoid(np.dot(X_, self.thetaLoss))[0]\n",
        "\n",
        "    return np.argmax([loss, tie, win]) - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwgN2rf2zyhB"
      },
      "source": [
        "# Train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "swqkGXL29N5r"
      },
      "outputs": [],
      "source": [
        "N = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "cellView": "form",
        "id": "SdHO3sfCz01L"
      },
      "outputs": [],
      "source": [
        "# @title Prepare train and test data\n",
        "train_match_data, train_team_data = getData(scraped_data['matches'], -N)\n",
        "train_noTieMatch_data, train_noTieTeam_data = getData(scraped_data['matches'], -N, True)\n",
        "\n",
        "test_match_data = {}\n",
        "for match_id in match_data:\n",
        "  if match_id not in train_match_data:\n",
        "    test_match_data[match_id] = match_data[match_id]\n",
        "ground = [classify(test_match_data[match_id][0]) for match_id in test_match_data]\n",
        "\n",
        "test_noTieMatch_data = {}\n",
        "for match_id in noTieMatch_data:\n",
        "  if match_id not in train_noTieMatch_data:\n",
        "    test_noTieMatch_data[match_id] = noTieMatch_data[match_id]\n",
        "noTieGround = [classify(test_noTieMatch_data[match_id][0]) for match_id in test_noTieMatch_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V1Y5HeSPsSr",
        "outputId": "24b12f26-f501-4aa3-e906-c3c3b61a174b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.4897959183673469\n",
            "Ties not included: 0.5052631578947369\n"
          ]
        }
      ],
      "source": [
        "# @title Statistics\n",
        "# with ties\n",
        "stats = Statistics(train_match_data)\n",
        "stats_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  stats_pred.append(classify(stats.Predict()))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(stats_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieStats = Statistics(train_noTieMatch_data)\n",
        "noTieStats_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieStats_pred.append(classify(noTieStats.Predict(), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieStats_pred) == np.array(noTieGround)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title k-mean Clustering - 2 clusters\n",
        "# with ties\n",
        "kMeanCluster2 = kMeanCluster(2, train_match_data)\n",
        "kMeanCluster2_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  kMeanCluster2_pred.append(classify(kMeanCluster2.Predict(test_match_data[match_id][1], test_match_data[match_id][2], train_noTieTeam_data)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(kMeanCluster2_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieKMeanCluster2 = kMeanCluster(2, train_noTieMatch_data)\n",
        "noTieKMeanCluster2_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieKMeanCluster2_pred.append(classify(noTieKMeanCluster2.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], train_noTieTeam_data), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieKMeanCluster2_pred) == np.array(noTieGround)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "susS_YZWxkUL",
        "outputId": "1b495a39-24ee-4bc1-da43-fb149103c872"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.11224489795918367\n",
            "Ties not included: 0.49473684210526314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title k-mean Clustering - 7 clusters\n",
        "# with ties\n",
        "kMeanCluster7 = kMeanCluster(7, train_match_data)\n",
        "kMeanCluster7_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  kMeanCluster7_pred.append(classify(kMeanCluster7.Predict(test_match_data[match_id][1], test_match_data[match_id][2], train_noTieTeam_data)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(kMeanCluster7_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieKMeanCluster7 = kMeanCluster(7, train_noTieMatch_data)\n",
        "noTieKMeanCluster7_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieKMeanCluster7_pred.append(classify(noTieKMeanCluster7.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], train_noTieTeam_data), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieKMeanCluster7_pred) == np.array(noTieGround)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtoNFiq9Qn8S",
        "outputId": "a3ce9128-82e9-4a70-b6a6-45fd6006766e",
        "cellView": "form"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.21428571428571427\n",
            "Ties not included: 0.5263157894736842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title k-mean Clustering - 8 clusters\n",
        "# with ties\n",
        "kMeanCluster8 = kMeanCluster(8, train_match_data)\n",
        "kMeanCluster8_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  kMeanCluster8_pred.append(classify(kMeanCluster8.Predict(test_match_data[match_id][1], test_match_data[match_id][2], train_noTieTeam_data)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(kMeanCluster8_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieKMeanCluster8 = kMeanCluster(8, train_noTieMatch_data)\n",
        "noTieKMeanCluster8_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieKMeanCluster8_pred.append(classify(noTieKMeanCluster8.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], train_noTieTeam_data), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieKMeanCluster8_pred) == np.array(noTieGround)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "qYTjVY1gw5GJ",
        "outputId": "d7d12867-de1e-4004-d608-93c30ea77e0e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.5306122448979592\n",
            "Ties not included: 0.5263157894736842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G7BnR5yCtC0B",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Hierarchical clustering - 0.1 with ties\n",
        "acc = 0.1\n",
        "# with ties\n",
        "cluster = HierarchicalClustering(average_linkage, euclidean_dist, train_match_data, acc)\n",
        "cluster_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  cluster_pred.append(classify(cluster.Predict(test_match_data[match_id][1], test_match_data[match_id][2], team_data)))\n",
        "\n",
        "print(\"\\rTies included:\", np.average(np.array(cluster_pred) == np.array(ground)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Hierarchical clustering - 0.1 without ties\n",
        "acc = 0.1\n",
        "# without ties\n",
        "noTieCluster = HierarchicalClustering(average_linkage, euclidean_dist, train_noTieMatch_data, acc)\n",
        "noTieCluster_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieCluster_pred.append(classify(noTieCluster.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], train_noTieTeam_data), False))\n",
        "\n",
        "print(\"\\rTies not included:\", np.average(np.array(noTieCluster_pred) == np.array(noTieGround)))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "edmBOrxKPkqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "cellView": "form",
        "id": "Ejq9r8Kr08tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2243f6-4ae8-4ccc-d317-b0d3f0f83239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.5510204081632653\n",
            "Ties not included: 0.631578947368421\n"
          ]
        }
      ],
      "source": [
        "# @title KNN - 3\n",
        "# with ties\n",
        "knn3 = KNN(3, train_team_data, train_match_data)\n",
        "knn3_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  knn3_pred.append(classify(knn3.Predict(test_match_data[match_id][1], test_match_data[match_id][2], True)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(knn3_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieKnn3 = KNN(3, train_noTieTeam_data, train_noTieMatch_data)\n",
        "noTieKnn3_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieKnn3_pred.append(classify(noTieKnn3.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], True), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieKnn3_pred) == np.array(noTieGround)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "cellView": "form",
        "id": "cNPi24ismcYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b521ea56-9ccd-4548-ec45-d6435bc8341f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.5408163265306123\n",
            "Ties not included: 0.6421052631578947\n"
          ]
        }
      ],
      "source": [
        "# @title KNN - 5\n",
        "# with ties\n",
        "knn5 = KNN(5, train_team_data, train_match_data)\n",
        "knn5_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  knn5_pred.append(classify(knn5.Predict(test_match_data[match_id][1], test_match_data[match_id][2], True)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(knn5_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieKnn5 = KNN(5, train_noTieTeam_data, train_noTieMatch_data)\n",
        "noTieKnn5_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieKnn5_pred.append(classify(noTieKnn5.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], True), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieKnn5_pred) == np.array(noTieGround)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "cellView": "form",
        "id": "tmYvk-simnmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d2756e-c791-4dad-a8c7-c5025c5b8477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.5306122448979592\n",
            "Ties not included: 0.6631578947368421\n"
          ]
        }
      ],
      "source": [
        "# @title KNN - 7\n",
        "# with ties\n",
        "knn7 = KNN(7, train_team_data, train_match_data)\n",
        "knn7_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  knn7_pred.append(classify(knn7.Predict(test_match_data[match_id][1], test_match_data[match_id][2], True)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(knn7_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieKnn7 = KNN(7, train_noTieTeam_data, train_noTieMatch_data)\n",
        "noTieKnn7_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieKnn7_pred.append(classify(noTieKnn7.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], True), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieKnn7_pred) == np.array(noTieGround)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "cellView": "form",
        "id": "SlHTPeTY58S-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b45ac81-0bf8-4bb4-d816-f9cb9dc143e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.673469387755102\n",
            "Ties not included: 0.6947368421052632\n"
          ]
        }
      ],
      "source": [
        "# @title Linear regression\n",
        "# with ties\n",
        "linreg = LinReg(train_match_data)\n",
        "linreg_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  linreg_pred.append(classify(linreg.Predict(test_match_data[match_id][1], test_match_data[match_id][2], team_data)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(linreg_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieLinreg = LinReg(train_noTieMatch_data)\n",
        "noTieLinreg_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieLinreg_pred.append(classify(linreg.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], train_noTieTeam_data), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieLinreg_pred) == np.array(noTieGround)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ElDBWvQhMO79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "98d5be02-46d2-4e06-9ef9-fd7418a75b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ties included: 0.6836734693877551\n",
            "Ties not included: 0.6947368421052632\n"
          ]
        }
      ],
      "source": [
        "# @title Logistic regression\n",
        "# with ties\n",
        "logreg = LogReg(train_match_data)\n",
        "logreg_pred = []\n",
        "\n",
        "for match_id in test_match_data:\n",
        "  logreg_pred.append(classify(logreg.Predict(test_match_data[match_id][1], test_match_data[match_id][2], team_data)))\n",
        "\n",
        "print(\"Ties included:\", np.average(np.array(logreg_pred) == np.array(ground)))\n",
        "\n",
        "# without ties\n",
        "noTieLogreg = LogReg(train_noTieMatch_data)\n",
        "noTieLogreg_pred = []\n",
        "\n",
        "for match_id in test_noTieMatch_data:\n",
        "  noTieLogreg_pred.append(classify(noTieLogreg.Predict(test_noTieMatch_data[match_id][1], test_noTieMatch_data[match_id][2], train_noTieTeam_data), False))\n",
        "\n",
        "print(\"Ties not included:\", np.average(np.array(noTieLogreg_pred) == np.array(noTieGround)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "VBFEUPjNChfb",
        "1ePQ7qQm9Nj4",
        "08F2CIEs8GGN"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMXWFWvBynZx8OhvDZ8BR6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}