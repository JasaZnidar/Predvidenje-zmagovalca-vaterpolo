{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasaZnidar/Predvidenje-zmagovalca-vaterpolo/blob/main/Diplomska_naloga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVXdEg3IE6jY"
      },
      "source": [
        "# Setup enviroment and imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBFEUPjNChfb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qckgRTSCkiJ",
        "outputId": "9b6fbd57-b56c-4315-c136-2d5d927ac3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/pyg_lib-0.4.0%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_sparse-0.6.18%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_cluster-1.6.3%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (943 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.4/943.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.25.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt22cu121 torch_cluster-1.6.3+pt22cu121 torch_scatter-2.1.2+pt22cu121 torch_sparse-0.6.18+pt22cu121 torch_spline_conv-1.2.2+pt22cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
        "!pip install torch torchvision torchaudio -f https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
        "!pip install torch-geometric\n",
        "!pip install torcheval\n",
        "!pip install scikit-plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_bTeA4IClUF"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pQMPL8B7EWKB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "from torch_geometric import nn, sampler\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric import transforms as T\n",
        "from torch_geometric import loader\n",
        "from torcheval.metrics import R2Score, MeanSquaredError\n",
        "import tqdm\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCsW9wIPMGhm"
      },
      "source": [
        "## Other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ongtkmPAMJQs"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utTRzV2s254U"
      },
      "source": [
        "# Analizing scraped data and create graph\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Zipped test.json file"
      ],
      "metadata": {
        "id": "eN83x5Kyt_-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with requests.get(\"https://github.com/JasaZnidar/totalwaterpolo-web-scraper/raw/master/test.zip\", ) as r:\n",
        "  ZipFile(BytesIO(r.content), \"r\").extractall()"
      ],
      "metadata": {
        "id": "hdczE6M5uFQd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIb_W7__9gwk"
      },
      "source": [
        "## Get scraped data from github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cvzBR3WG3F7G"
      },
      "outputs": [],
      "source": [
        "# open raw data scraped from the website\n",
        "with open(\"/content/test.json\") as f:\n",
        "    scraped_data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUCmRM4IpJBF"
      },
      "source": [
        "## Data generating function\n",
        "We will create a function that will create HeteroData from scraped data before a selected date. This will be used to create training data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### player_in_match functions"
      ],
      "metadata": {
        "id": "dfTaSYJuyRhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average(history: list[list[float]]) -> list[float]:\n",
        "  ret = [0]*len(history[0])\n",
        "\n",
        "  for match in history:\n",
        "    for i in range(len(match)):\n",
        "      ret[i] += match[i]\n",
        "\n",
        "  for i in range(len(ret)):\n",
        "    ret[i] /= len(history)\n",
        "\n",
        "  return ret"
      ],
      "metadata": {
        "id": "S8ZhkBKFvtWZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create graph from json"
      ],
      "metadata": {
        "id": "cvLTk7Dkstuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createData(data: dict, start: int=0, stop: int=-1) -> HeteroData:\n",
        "  # data\n",
        "  ret_data = HeteroData()\n",
        "\n",
        "  #=============================================================================\n",
        "  # Matrices that will define the graph\n",
        "  #=============================================================================\n",
        "  # player (player)\n",
        "  player_dim = 5\n",
        "  player_matrix = torch.empty(0, player_dim, dtype=torch.float32)\n",
        "\n",
        "  # player in a match (played_in_match)\n",
        "  playerInMatch_dim = 10\n",
        "  playerInMatch_matrix = torch.empty(0, playerInMatch_dim, dtype=torch.float32)\n",
        "\n",
        "  # team (team)\n",
        "  team_dim = 0\n",
        "  team_matrix = torch.empty(0, team_dim, dtype=torch.float32)\n",
        "\n",
        "  # team in a match (team_in_match)\n",
        "  teamInMatch_dim = 3\n",
        "  teamInMatch_matrix = torch.empty(0, teamInMatch_dim, dtype=torch.float32)\n",
        "\n",
        "  # player instance relation (player, player_instance, played_in_match)\n",
        "  playerInstance_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "\n",
        "  # played relation (played_in_match, played, team_in_match)\n",
        "  played_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "  played_attr = torch.empty(1, 0, dtype=torch.float32)\n",
        "\n",
        "  # team participated in a match (team, team_instance, team_in_match)\n",
        "  teamInstance_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "\n",
        "  # match result (team_in_match, result, team_in_match)\n",
        "  result_matrix = torch.empty(2, 0, dtype=torch.long)\n",
        "  result_attr = torch.empty(1, 0, dtype=torch.float32)\n",
        "  # reversed relations\n",
        "  result_rev_attr = torch.empty(1, 0, dtype=torch.float32)\n",
        "\n",
        "  #=============================================================================\n",
        "  # Other data\n",
        "  #=============================================================================\n",
        "  player_match_history = {}\n",
        "\n",
        "  #=============================================================================\n",
        "  # Sort matches in order of date, and filter out the matches that happened\n",
        "  # after the specified date\n",
        "  #=============================================================================\n",
        "  # filter out matches\n",
        "  sorted_match_ids = []\n",
        "  breakpoint_match_id = (\"\", -1)\n",
        "  for match_id in data['matches']:\n",
        "    if 'date' in data['matches'][match_id]:\n",
        "      sorted_match_ids.append((match_id, data['matches'][match_id]['date']))\n",
        "\n",
        "  # sort matches\n",
        "  sorted_match_ids = sorted(sorted_match_ids, key=lambda t: t[1])\n",
        "\n",
        "\n",
        "  #=============================================================================\n",
        "  # Loop through the matches and fill out the matrices\n",
        "  #=============================================================================\n",
        "  players_id_index = {}\n",
        "  cumulative_player_data = {}\n",
        "  cumulative_team_data = {}\n",
        "\n",
        "  for index in range(len(sorted_match_ids)):\n",
        "    # exit loop if enough matches have been added\n",
        "    if result_matrix.shape[1] == stop - start:\n",
        "      break\n",
        "    match_id, _ = sorted_match_ids[index]\n",
        "    match_data = data['matches'][match_id]\n",
        "\n",
        "    # check if match is relevant (at least 7 players in each team)\n",
        "    if len(match_data['lineup']['home']) < 7 or len(match_data['lineup']['away']) < 7:\n",
        "      continue\n",
        "\n",
        "    # result of match\n",
        "    if index >= start:\n",
        "      result_matrix = torch.cat((result_matrix, torch.empty((2, 1))), dim=1)\n",
        "      result_attr = torch.cat((result_attr, torch.empty((1, 1))), dim=1)\n",
        "      result_rev_attr = torch.cat((result_rev_attr, torch.empty((1, 1))), dim=1)\n",
        "      if match_data['result']['home'] > match_data['result']['away']:\n",
        "        result_attr[0, -1] = 1.0\n",
        "        result_rev_attr[0, -1] = 0.0\n",
        "      elif match_data['result']['home'] < match_data['result']['away']:\n",
        "        result_attr[0, -1] = 0.0\n",
        "        result_rev_attr[0, -1] = 1.0\n",
        "      else:\n",
        "        result_attr[0, -1] = 0.5\n",
        "        result_rev_attr[0, -1] = 0.5\n",
        "\n",
        "    # go through the lineup\n",
        "    for team in ['home', 'away']:\n",
        "      # create teamInMatch\n",
        "      team_key = match_data['name'][team]\n",
        "\n",
        "      # if there is no instance of the team, we need a new team\n",
        "      if not team_key in cumulative_team_data:\n",
        "        cumulative_team_data[team_key] = {\n",
        "            \"data\": [[0, 0, 0 if team == \"home\" else 1]],   # [[wins, matches, home/away]]\n",
        "            \"last index\": teamInMatch_matrix.size(dim=0),\n",
        "            \"team index\": team_matrix.size(dim=0)\n",
        "        }\n",
        "\n",
        "        # add new team\n",
        "        if index >= start:\n",
        "          team_matrix = torch.cat((team_matrix, torch.empty(1, team_dim)), dim=0)\n",
        "\n",
        "      # update cumulative_team_data\n",
        "      cumulative_team_data[team_key]['data'][0][2] = 0 if team == \"home\" else 1\n",
        "      cumulative_team_data[team_key]['last index'] = teamInMatch_matrix.size(dim=0)\n",
        "      # add new teamInMatch\n",
        "      if index >= start:\n",
        "        teamInMatch_matrix = torch.cat((teamInMatch_matrix, torch.Tensor(cumulative_team_data[team_key]['data'])), dim=0)\n",
        "\n",
        "      # connect teamInMatch to enemy teamInMatch\n",
        "      if index >= start:\n",
        "        result_matrix[0 if team == \"home\" else 1, -1] = cumulative_team_data[team_key]['last index']\n",
        "\n",
        "      # connect team to teamInMatch\n",
        "      if index >= start:\n",
        "        teamInstance_matrix = torch.cat((teamInstance_matrix, torch.Tensor([[cumulative_team_data[team_key]['team index']], [cumulative_team_data[team_key]['last index']]])), dim=1)\n",
        "\n",
        "      # update cumulative_team_data\n",
        "      cumulative_team_data[team_key]['data'][0][0] += 1 if match_data['result'][team] > match_data['result']['away' if team == \"home\" else 'home'] else 0\n",
        "      cumulative_team_data[team_key]['data'][0][1] += 1\n",
        "\n",
        "\n",
        "      # loop through the lineup\n",
        "      for player_num in match_data['lineup'][team]:\n",
        "        player_id = match_data['lineup'][team][player_num]['id']\n",
        "\n",
        "        # check if player is in player matrix\n",
        "        if not player_id in players_id_index:\n",
        "          try:\n",
        "            player = data['players'][player_id]\n",
        "          except KeyError:\n",
        "            player = {\n",
        "                \"position\": '',\n",
        "                \"hand\": '',\n",
        "                \"height\": 0,\n",
        "                \"weight\": 0,\n",
        "                \"birth\": 0\n",
        "            }\n",
        "          players_id_index[player_id] = len(players_id_index.keys())\n",
        "\n",
        "          # player attributes to int\n",
        "          player_attr = torch.zeros((1, player_dim), dtype=torch.int32)\n",
        "          player_attr[0, 0] = player['birth']\n",
        "          player_attr[0, 1] = 1 if player['hand'] == \"R\" else -1 if player['hand'] == \"L\" else 0\n",
        "          player_attr[0, 2] = player['height'] if player['height'] else 0\n",
        "          match player['position']:\n",
        "            case '':\n",
        "              player_attr[0, 3] = 0\n",
        "            case 'Goalkeeper':\n",
        "              player_attr[0, 3] = 1\n",
        "            case 'Driver':\n",
        "              player_attr[0, 3] = 2\n",
        "            case 'Left Driver':\n",
        "              player_attr[0, 3] = 3\n",
        "            case 'Right Driver':\n",
        "              player_attr[0, 3] = 4\n",
        "            case 'Central Defender':\n",
        "              player_attr[0, 3] = 5\n",
        "            case 'Left Winger':\n",
        "              player_attr[0, 3] = 6\n",
        "            case 'Right Winger':\n",
        "              player_attr[0, 3] = 7\n",
        "            case 'Center Forward':\n",
        "              player_attr[0, 3] = 8\n",
        "          player_attr[0, 4] = player['weight'] if player['weight'] else 0\n",
        "\n",
        "          if index >= start:\n",
        "            # add player to player matrix\n",
        "            player_matrix = torch.cat((player_matrix, player_attr), dim=0)\n",
        "\n",
        "          # add player to cumulate data\n",
        "          cumulative_player_data[player_id] = {\n",
        "              \"data\": [0] * (playerInMatch_dim + 2),  # [goals, shots, assists, blocks, saves, exclusions, penalties, suspensions, brutalities, sprints won] + [matches, sprints]\n",
        "              \"last index\": playerInMatch_matrix.size(dim=0)\n",
        "          }\n",
        "\n",
        "        if player_id not in player_match_history:\n",
        "          player_match_history[player_id] = []\n",
        "        player_match_history[player_id].append([0] * (playerInMatch_dim + 2))\n",
        "\n",
        "        if index >= start:\n",
        "          # add new playerInMatch\n",
        "          playerInMatch_matrix = torch.cat((playerInMatch_matrix, torch.Tensor([cumulative_player_data[player_id]['data'][:-2]])), dim=0)\n",
        "          if not cumulative_player_data[player_id]['data'][-2] == 0:\n",
        "            playerInMatch_matrix[-1, :-1] /= cumulative_player_data[player_id]['data'][-2]\n",
        "          if not cumulative_player_data[player_id]['data'][-1] == 0:\n",
        "            playerInMatch_matrix[-1, -1] /= cumulative_player_data[player_id]['data'][-1]\n",
        "\n",
        "          # connect player to playerInMatch\n",
        "          playerInstance_matrix = torch.cat((playerInstance_matrix, torch.Tensor([[players_id_index[player_id]], [cumulative_player_data[player_id]['last index']]])), dim=1)\n",
        "\n",
        "          # connect playerInMatch to teamInMatch\n",
        "          played_matrix = torch.cat((played_matrix, torch.Tensor([[cumulative_player_data[player_id]['last index']], [cumulative_team_data[team_key]['last index']]])), dim=1)\n",
        "          played_attr = torch.cat((played_attr, torch.Tensor([[0 if player_num == \"1\" or player_num == \"13\" else 1]])), dim=1)\n",
        "\n",
        "        # update cumulative_player_data\n",
        "        cumulative_player_data[player_id]['data'][10] += 1  # played in a match\n",
        "\n",
        "    # update data with data from this match\n",
        "    # go throught ALL plays and update cumulative_player_data and cumulative_team_data\n",
        "    for play in match_data['plays']:\n",
        "      # check if a player was marked\n",
        "      if play['player_1'] == 0:\n",
        "        continue\n",
        "\n",
        "      # find teams\n",
        "      team_1 = play['team']\n",
        "      team_2 = \"home\" if team_1 == \"away\" else \"away\"\n",
        "\n",
        "      # find players who participated in the play\n",
        "      try:\n",
        "        id_1 = match_data['lineup'][team_1][str(play['player_1'])]['id']\n",
        "      except Exception as ex:\n",
        "        print(match_id, team_1, match_data['name'][team_1])\n",
        "        #print(json.dumps(match_data['lineup'][team_1], sort_keys=True, indent=4))\n",
        "        print(json.dumps(play, sort_keys=True, indent=4))\n",
        "        raise ex\n",
        "      id_2 = [0, 0] # depending on the play, the second player could be from the same team (first value is the opposing team)\n",
        "      if not play['player_2'] == 0:\n",
        "        if str(play['player_2']) in match_data['lineup'][team_2]:\n",
        "          id_2[0] = match_data['lineup'][team_2][str(play['player_2'])]['id']\n",
        "        if str(play['player_2']) in match_data['lineup'][team_1]:\n",
        "          id_2[1] = match_data['lineup'][team_1][str(play['player_2'])]['id']\n",
        "\n",
        "      # detect play type\n",
        "      if \"goal scored\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][0] += 1        # goals\n",
        "        player_match_history[id_1][-1][0] += 1\n",
        "        cumulative_player_data[id_1]['data'][1] += 1        # shots\n",
        "        player_match_history[id_1][-1][1] += 1\n",
        "        if not id_2[1] == 0:\n",
        "          cumulative_player_data[id_2]['data'][2] += 1      # assists\n",
        "          player_match_history[id_1][-1][2] += 1\n",
        "      elif \"exclusion\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][5] += 1        # exclusion\n",
        "        player_match_history[id_1][-1][5] += 1\n",
        "      elif \"penalty foul\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][6] += 1        # penalty\n",
        "        player_match_history[id_1][-1][6] += 1\n",
        "      elif \"shot missed\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][1] += 1        # shots\n",
        "        player_match_history[id_1][-1][1] += 1\n",
        "      elif \"shot saved\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][1] += 1        # shots\n",
        "        player_match_history[id_1][-1][1] += 1\n",
        "      elif \"shot blocked\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][1] += 1        # shots\n",
        "        player_match_history[id_1][-1][1] += 1\n",
        "        if not id_2[0] == 0:\n",
        "          cumulative_player_data[id_2[0]]['data'][3] += 1   # blocks\n",
        "          player_match_history[id_2][-1][3] += 1\n",
        "      elif \"suspention\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][7] += 1        # suspensions\n",
        "        player_match_history[id_1][-1][7] += 1\n",
        "      elif \"brutality\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][8] += 1        # brutalities\n",
        "        player_match_history[id_1][-1][8] += 1\n",
        "      elif \"sprint won\" in play['action']:\n",
        "        cumulative_player_data[id_1]['data'][9] += 1        # sprint won\n",
        "        player_match_history[id_1][-1][9] += 1\n",
        "        cumulative_player_data[id_1]['data'][11] += 1       # sprint\n",
        "        player_match_history[id_1][-1][11] += 1\n",
        "        if not id_2[0] == 0:\n",
        "          cumulative_player_data[id_2[0]]['data'][11] += 1  # sprint\n",
        "          player_match_history[id_1][-1][11] += 1\n",
        "\n",
        "  # save data\n",
        "  ret_data['player'].x = player_matrix\n",
        "  ret_data['player_in_match'].x = playerInMatch_matrix\n",
        "  ret_data['team'].x = team_matrix\n",
        "  ret_data['team_in_match'].x = teamInMatch_matrix\n",
        "\n",
        "  ret_data['player', 'player_instance', 'player_in_match'].edge_index = playerInstance_matrix.type(torch.long)\n",
        "  ret_data['player_in_match', 'player_instance_rev', 'player'].edge_index = playerInstance_matrix.flip([0]).type(torch.long)\n",
        "\n",
        "  ret_data['player_in_match', 'played', 'team_in_match'].edge_index = played_matrix.type(torch.long)\n",
        "  ret_data['player_in_match', 'played', 'team_in_match'].edge_attr = played_attr\n",
        "  ret_data['team_in_match', 'played_rev', 'player_in_match'].edge_index = played_matrix.flip([0]).type(torch.long)\n",
        "  ret_data['team_in_match', 'played_rev', 'player_in_match'].edge_attr = played_attr\n",
        "\n",
        "  ret_data['team', 'team_instance', 'team_in_match'].edge_index = teamInstance_matrix.type(torch.long)\n",
        "  ret_data['team_in_match', 'team_instance_rev', 'team'].edge_index = teamInstance_matrix.flip([0]).type(torch.long)\n",
        "\n",
        "  ret_data['team_in_match', 'result', 'team_in_match'].edge_index = result_matrix.type(torch.long)\n",
        "  ret_data['team_in_match', 'result', 'team_in_match'].edge_attr = result_attr\n",
        "  ret_data['team_in_match', 'result_rev', 'team_in_match'].edge_index = result_matrix.flip([0]).type(torch.long)\n",
        "  ret_data['team_in_match', 'result_rev', 'team_in_match'].edge_attr = result_rev_attr\n",
        "\n",
        "  P = '8440'\n",
        "  print(playerInMatch_matrix[ cumulative_player_data[P]['last index'] ])\n",
        "  print(player_match_history[P][-1])\n",
        "\n",
        "  return ret_data"
      ],
      "metadata": {
        "id": "ADqYuU2r_0As"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = createData(scraped_data)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "M5sFEFXSw-m3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286b5ad9-dbb6-478e-cc04-69b32e5d7275"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "[3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "HeteroData(\n",
            "  player={ x=[10356, 5] },\n",
            "  player_in_match={ x=[110227, 10] },\n",
            "  team={ x=[497, 0] },\n",
            "  team_in_match={ x=[8768, 3] },\n",
            "  (player, player_instance, player_in_match)={ edge_index=[2, 110227] },\n",
            "  (player_in_match, player_instance_rev, player)={ edge_index=[2, 110227] },\n",
            "  (player_in_match, played, team_in_match)={\n",
            "    edge_index=[2, 110227],\n",
            "    edge_attr=[1, 110227],\n",
            "  },\n",
            "  (team_in_match, played_rev, player_in_match)={\n",
            "    edge_index=[2, 110227],\n",
            "    edge_attr=[1, 110227],\n",
            "  },\n",
            "  (team, team_instance, team_in_match)={ edge_index=[2, 8768] },\n",
            "  (team_in_match, team_instance_rev, team)={ edge_index=[2, 8768] },\n",
            "  (team_in_match, result, team_in_match)={\n",
            "    edge_index=[2, 4384],\n",
            "    edge_attr=[1, 4384],\n",
            "  },\n",
            "  (team_in_match, result_rev, team_in_match)={\n",
            "    edge_index=[2, 4384],\n",
            "    edge_attr=[1, 4384],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['player'].x[:5, :5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFrCh-_rsfqO",
        "outputId": "db7c6aaf-0ae8-4623-a2ab-5d1e4decb5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5591e+04, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [4.5142e+04, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [4.8020e+04, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [4.5137e+04, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [4.5550e+04, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split data into training and validation"
      ],
      "metadata": {
        "id": "tGflFDiyeT9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values to define the scope of the training and validation."
      ],
      "metadata": {
        "id": "P-xP4QJPeobL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training = -1\n",
        "validate = 1000"
      ],
      "metadata": {
        "id": "cpVJm9J_eafv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If train or validate are not bigger then 0, their values are addapted acordingly to fully utilize the avaliable data."
      ],
      "metadata": {
        "id": "f3fAZGh2evKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if training <= 0 and validate <= 0:\n",
        "  validate = 1\n",
        "  training = data[\"team_in_match\", \"result\", \"team_in_match\"].edge_index.size(dim=1) - 1\n",
        "elif training <= 0:\n",
        "  training = data[\"team_in_match\", \"result\", \"team_in_match\"].edge_index.size(dim=1) - validate\n",
        "elif validate <= 0:\n",
        "  validate = data[\"team_in_match\", \"result\", \"team_in_match\"].edge_index.size(dim=1) - training\n"
      ],
      "metadata": {
        "id": "G5uG5xxTe1C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = createData(scraped_data, stop=training)\n",
        "print(train_data)\n",
        "val_data = createData(scraped_data, start=training, stop=(training + validate))\n",
        "print(\"\\n\", val_data)"
      ],
      "metadata": {
        "id": "_q5a5KoX2rFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3f0cdc-3891-4931-86b8-de3712f1431d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  player={ x=[8941, 5] },\n",
            "  player_in_match={ x=[84384, 10] },\n",
            "  team={ x=[437, 0] },\n",
            "  team_in_match={ x=[6768, 3] },\n",
            "  (player, player_instance, player_in_match)={ edge_index=[2, 84384] },\n",
            "  (player_in_match, player_instance_rev, player)={ edge_index=[2, 84384] },\n",
            "  (player_in_match, played, team_in_match)={\n",
            "    edge_index=[2, 84384],\n",
            "    edge_attr=[1, 84384],\n",
            "  },\n",
            "  (team_in_match, played_rev, player_in_match)={\n",
            "    edge_index=[2, 84384],\n",
            "    edge_attr=[1, 84384],\n",
            "  },\n",
            "  (team, team_instance, team_in_match)={ edge_index=[2, 6768] },\n",
            "  (team_in_match, team_instance_rev, team)={ edge_index=[2, 6768] },\n",
            "  (team_in_match, result, team_in_match)={\n",
            "    edge_index=[2, 3384],\n",
            "    edge_attr=[1, 3384],\n",
            "  },\n",
            "  (team_in_match, result_rev, team_in_match)={\n",
            "    edge_index=[2, 3384],\n",
            "    edge_attr=[1, 3384],\n",
            "  }\n",
            ")\n",
            "\n",
            " HeteroData(\n",
            "  player={ x=[1442, 5] },\n",
            "  player_in_match={ x=[25919, 10] },\n",
            "  team={ x=[60, 0] },\n",
            "  team_in_match={ x=[2000, 3] },\n",
            "  (player, player_instance, player_in_match)={ edge_index=[2, 25919] },\n",
            "  (player_in_match, player_instance_rev, player)={ edge_index=[2, 25919] },\n",
            "  (player_in_match, played, team_in_match)={\n",
            "    edge_index=[2, 25919],\n",
            "    edge_attr=[1, 25919],\n",
            "  },\n",
            "  (team_in_match, played_rev, player_in_match)={\n",
            "    edge_index=[2, 25919],\n",
            "    edge_attr=[1, 25919],\n",
            "  },\n",
            "  (team, team_instance, team_in_match)={ edge_index=[2, 2000] },\n",
            "  (team_in_match, team_instance_rev, team)={ edge_index=[2, 2000] },\n",
            "  (team_in_match, result, team_in_match)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1, 1000],\n",
            "  },\n",
            "  (team_in_match, result_rev, team_in_match)={\n",
            "    edge_index=[2, 1000],\n",
            "    edge_attr=[1, 1000],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd1yf4Tn0sKT"
      },
      "source": [
        "# Machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder and Decoder"
      ],
      "metadata": {
        "id": "mC2fPbM1pRTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, layer=nn.GATConv, device='cpu'):\n",
        "    super().__init__()\n",
        "\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    self.convs.append(layer(in_channels, hidden_channels))\n",
        "    for _ in range(1, layers-1):\n",
        "      self.convs.append(layer(hidden_channels, hidden_channels))\n",
        "    self.convs.append(layer(hidden_channels, out_channels))\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for conv in self.convs[:-1]:\n",
        "      x = conv(x, edge_index)\n",
        "      x = x.relu()\n",
        "    x = self.convs[-1](x, edge_index)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for conv in self.convs[:-1]:\n",
        "      x = conv(x, edge_index)\n",
        "      x = x.relu()\n",
        "    x = self.convs[-1](x, edge_index)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2):\n",
        "    super().__init__()\n",
        "\n",
        "    self.lins = torch.nn.ModuleList()\n",
        "    self.lins.append(nn.Linear(in_channels, hidden_channels))\n",
        "    for _ in range(1, layers-1):\n",
        "      self.lins.append(nn.Linear(hidden_channels, hidden_channels))\n",
        "    self.lins.append(nn.Linear(hidden_channels, out_channels))\n",
        "\n",
        "  def forward(self, x_dict, edge_label_index):\n",
        "    row, col = edge_label_index\n",
        "    x = torch.cat([x_dict['team'][row], x_dict['team'][col]], dim=-1)\n",
        "\n",
        "    for lin in self.lins[:-1]:\n",
        "      x = lin(x)\n",
        "      x = x.relu()\n",
        "    x = self.lins[-1](x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "WzKHYzGCpA7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple module"
      ],
      "metadata": {
        "id": "ydDxJlvA53dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class basicModule(torch.nn.Module):\n",
        "  def __init__(self, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.lin = torch.nn.Linear(2, 1).to(self.device)\n",
        "\n",
        "  def forward(self, edge, edge_index):\n",
        "    x = torch.zeros([edge_index.shape[1], 2])\n",
        "    x[:, 0] = edge[edge_index[0], 2]\n",
        "    x[:, 1] = edge[edge_index[1], 2]\n",
        "\n",
        "    x = self.lin(x.to(self.device))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "XFSBHwy559fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6mEs7cHcx51"
      },
      "source": [
        "## GCN module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XewxSir-1aRy"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, layers=2, device='cpu'):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    if layers == 1:\n",
        "      self.gcn = nn.GCNConv(in_channels, out_channels, add_self_loops=False)\n",
        "    else:\n",
        "      self.gcn = torch.nn.ModuleList()\n",
        "      self.gcn.append(nn.GCNConv(in_channels, hidden_channels, add_self_loops=False))\n",
        "      for _ in range(1, layers-1):\n",
        "        self.gcn.append(nn.GCNConv(hidden_channels, hidden_channels, add_self_loops=False))\n",
        "      self.gcn.append(nn.GCNConv(hidden_channels, out_channels, add_self_loops=False))\n",
        "\n",
        "    #self.gcn = nn.to_hetero(self.gcn, train_data.metadata(), aggr='sum')\n",
        "\n",
        "    self.gcn.to(self.device)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x.to(self.device)\n",
        "\n",
        "    for module in self.gcn:\n",
        "      x = module(x, edge_index)\n",
        "      x = x.relu()\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAGEConv module"
      ],
      "metadata": {
        "id": "IjGwyEOAnulm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, encode_layers=2, edecode_layers=2):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(\n",
        "        in_channels,\n",
        "        hidden_channels,\n",
        "        hidden_channels,\n",
        "        encode_layers,\n",
        "        lambda in_c, hidden_c: nn.SAGEConv(in_c, hidden_c, add_self_loops=False)\n",
        "    )\n",
        "    self.encoder = nn.to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "\n",
        "    self.decoder = Decoder(hidden_channels, hidden_channels, out_channels, edecode_layers)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # encode\n",
        "    x = self.encoder(x, edge_index)\n",
        "\n",
        "    # decode\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "49R8gfrJntf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT Module"
      ],
      "metadata": {
        "id": "VzviYSH_pGYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, encode_layers=2, edecode_layers=2):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(\n",
        "        in_channels,\n",
        "        hidden_channels,\n",
        "        hidden_channels,\n",
        "        encode_layers,\n",
        "        lambda in_c, hidden_c: nn.GATConv(in_c, hidden_c, add_self_loops=False)\n",
        "    )\n",
        "    self.encoder = nn.to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "\n",
        "    self.decoder = Decoder(hidden_channels, hidden_channels, out_channels, edecode_layers)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # encode\n",
        "    x = self.encoder(x, edge_index)\n",
        "\n",
        "    # decode\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "Na4Yn23JpI_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1nbDFItfvHP"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "size = 64\n",
        "iterations = 3\n",
        "\n",
        "neighbors = {\n",
        "    ('player', 'player_instance', 'player_in_match'): [20]*iterations,\n",
        "    ('player_in_match', 'player_instance_rev', 'player'): [1]*iterations,\n",
        "    ('player_in_match', 'played', 'team_in_match'): [1]*iterations,\n",
        "    ('team_in_match', 'played_rev', 'player_in_match'): [13]*iterations,\n",
        "    ('team', 'team_instance', 'team_in_match'): [20]*iterations,\n",
        "    ('team_in_match', 'team_instance_rev', 'team'): [1]*iterations,\n",
        "    ('team_in_match', 'result', 'team_in_match'): [1]*iterations,\n",
        "    ('team_in_match', 'result_rev', 'team_in_match'): [1]*iterations\n",
        "}\n",
        "\n",
        "edgeIndex = tuple((link, train_data[link].edge_index) for link in train_data.metadata()[1])\n",
        "\n",
        "matchLoader = loader.NeighborLoader(\n",
        "    train_data.to(device),\n",
        "    num_neighbors=neighbors,\n",
        "    batch_size=size,\n",
        "    input_nodes='team_in_match',\n",
        "    # temporal_strategy='last'  # za izbiro zgodovino tekem?\n",
        "    # is_sorted=True  # edge indexi so urejeni časovno\n",
        ")\n",
        "\n",
        "matchData = next(iter(matchLoader))\n",
        "print(matchData)"
      ],
      "metadata": {
        "id": "stsEM2f69lFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "264c969c-9f77-4e25-a89d-406c79c29d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torch_geometric.loader' has no attribute 'HeteroSamplerOutput'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1a418c1b42fb>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0medgeIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m matchLoader = loader.HeteroSamplerOutput(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch_geometric.loader' has no attribute 'HeteroSamplerOutput'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Module"
      ],
      "metadata": {
        "id": "nXWygaeMj5Xu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m30eApwATQwV"
      },
      "outputs": [],
      "source": [
        "basic = basicModule(device=device)\n",
        "\n",
        "optimizer = torch.optim.Adam(basic.parameters(), lr=0.001)\n",
        "r2 = R2Score().to(device)\n",
        "mse = MeanSquaredError().to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = total_examples = 0\n",
        "  optimizer.zero_grad()\n",
        "  pred = basic(\n",
        "      train_data['team_in_match'].x,\n",
        "      train_data['team_in_match', 'result', 'team_in_match'].edge_index\n",
        "  ).T.to(device)\n",
        "  ground_truth = train_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "  loss = torch.nn.functional.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  total_loss += float(loss) * pred.numel()\n",
        "  total_examples += pred.numel()\n",
        "  r2.update(pred.T, ground_truth.T)\n",
        "  mse.update(pred.T, ground_truth.T)\n",
        "\n",
        "  #print(f\"Epoch: {epoch+1:03d}, Loss: {total_loss / total_examples:.4f}, R2: {r2.compute()}, MSE: {mse.compute()}\")\n",
        "\n",
        "# validate\n",
        "pred = basic(\n",
        "    val_data['team_in_match'].x,\n",
        "    val_data['team_in_match', 'result', 'team_in_match'].edge_index\n",
        ").T.to(device)\n",
        "ground_truth = val_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "r2.update(pred.T, ground_truth.T)\n",
        "mse.update(pred.T, ground_truth.T)\n",
        "print(f\"Validation\\n\\tR2: {r2.compute()}\\n\\tMSE: {mse.compute()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCN"
      ],
      "metadata": {
        "id": "sCjc3rNjj8V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GCNModule = GCN(64, 64, 1, device=device)\n",
        "\n",
        "optimizer = torch.optim.Adam(GCNModule.parameters(), lr=0.001)\n",
        "\n",
        "train_edge_index_dict = {edge: train_data[edge].edge_index for edge in train_data.metadata()[1]}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = total_examples = 0\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  train_data.to(device)\n",
        "  pred = GCNModule(\n",
        "      train_data['team_in_match'].x,\n",
        "      train_data['team_in_match', 'result', 'team_in_match'].edge_index\n",
        "  ).T.to(device)\n",
        "  ground_truth = train_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "  loss = torch.nn.functional.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  total_loss += float(loss) * pred.numel()\n",
        "  total_examples += pred.numel()\n",
        "  r2.update(pred.T, ground_truth.T)\n",
        "  mse.update(pred.T, ground_truth.T)\n",
        "\n",
        "  #print(f\"Epoch: {epoch+1:03d}, Loss: {total_loss / total_examples:.4f}, R2: {r2.compute()}, MSE: {mse.compute()}\")\n",
        "\n",
        "# validate\n",
        "pred = GCNModule(\n",
        "    val_data['team_in_match'].x,\n",
        "    val_data['team_in_match', 'result', 'team_in_match'].edge_index\n",
        ").T.to(device)\n",
        "ground_truth = val_data['team_in_match', 'result', 'team_in_match'].edge_attr.to(device)\n",
        "r2.update(pred.T, ground_truth.T)\n",
        "mse.update(pred.T, ground_truth.T)\n",
        "print(f\"Validation\\n\\tR2: {r2.compute()}\\n\\tMSE: {mse.compute()}\")"
      ],
      "metadata": {
        "id": "1ZlESIS3jceS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAT"
      ],
      "metadata": {
        "id": "xgkH34eHj-JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GATModule = GAT(64, 64, 1).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(GATModule.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range(training):\n",
        "    total_loss = total_examples = 0\n",
        "    optimizer.zero_grad()\n",
        "    train_data.to(device)\n",
        "    pred = GATModule(train_data['team_in_match'].x, train_data['team_in_match', 'result', 'team_in_match'].edge_index[:, i])\n",
        "    ground_truth = train_data['team_in_match', 'result', 'team_in_match'].edge_attr[:, i]\n",
        "    loss = torch.nn.functional.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += float(loss) * pred.numel()\n",
        "    total_examples += pred.numel()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "QS6s_4Vkjg5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZlT0tODsL22"
      },
      "source": [
        "## Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7-fkM0MwYXf"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "ground_truths = []\n",
        "\n",
        "for i in range(validate):\n",
        "  with torch.no_grad():\n",
        "    preds.append(model(val_data['team_in_match'].x, val_data['team_in_match', 'result', 'team_in_match'].edge_index[:, i]))\n",
        "    ground_truths.append(val_data['team_in_match', 'result', 'team_in_match'].edge_attr[:, i])\n",
        "\n",
        "preds = [torch.Tensor([0.0]) if p[0] < 0.33 else torch.Tensor([1.0]) for p in preds]\n",
        "ground_truths = [torch.Tensor([0.0]) if gt[0] < 0.33 else torch.Tensor([1.0]) for gt in ground_truths]\n",
        "\n",
        "auc = roc_auc_score(ground_truths, preds)\n",
        "fpr, tpr, _ = roc_curve(ground_truths, preds)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color=\"red\", lw=2, linestyle=\"--\")\n",
        "plt.plot(fpr,tpr, color=\"navy\")\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "print(f\"Validation AUC: {auc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aVXdEg3IE6jY",
        "VBFEUPjNChfb",
        "Z_bTeA4IClUF",
        "zCsW9wIPMGhm",
        "DIb_W7__9gwk",
        "tGflFDiyeT9P",
        "mC2fPbM1pRTw",
        "ydDxJlvA53dw",
        "t6mEs7cHcx51",
        "IjGwyEOAnulm",
        "VzviYSH_pGYW",
        "nXWygaeMj5Xu"
      ],
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPSXnbyYSi1gVtIYCc+a2gJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}