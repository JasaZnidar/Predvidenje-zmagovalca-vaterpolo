{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VBFEUPjNChfb",
        "zCsW9wIPMGhm",
        "utTRzV2s254U",
        "DIb_W7__9gwk",
        "oUCmRM4IpJBF",
        "AmOTWVvxvYds",
        "NP9_HA8vw1Ir",
        "bsFn03a0xD2D",
        "HZUiLQUDOsGy",
        "UkwQEt9rxdLs",
        "vQmScrKDPQHr"
      ],
      "authorship_tag": "ABX9TyPB5KX+ZOa8pJmg0YWrtl02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasaZnidar/Predvidenje-zmagovalca-vaterpolo/blob/main/Diplomska_naloga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup enviroment and imports"
      ],
      "metadata": {
        "id": "aVXdEg3IE6jY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "VBFEUPjNChfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "!pip install torch-geometric\n",
        "!pip install scikit-plot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qckgRTSCkiJ",
        "outputId": "1cee71a6-71ad-4609-8a8a-a5a731945b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/pyg_lib-0.4.0%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.25.2)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt21cu121 torch_cluster-1.6.3+pt21cu121 torch_scatter-2.1.2+pt21cu121 torch_sparse-0.6.18+pt21cu121 torch_spline_conv-1.2.2+pt21cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.3.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.0\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Z_bTeA4IClUF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQMPL8B7EWKB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from urllib.request import urlopen\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.utils.convert import from_networkx\n",
        "from torch_geometric import nn\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric import transforms as T\n",
        "from torch_geometric.loader import LinkNeighborLoader, NeighborLoader\n",
        "import tqdm\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other"
      ],
      "metadata": {
        "id": "zCsW9wIPMGhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "ongtkmPAMJQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analizing scraped data and create graph\n",
        "\n"
      ],
      "metadata": {
        "id": "utTRzV2s254U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get scraped data from github repository"
      ],
      "metadata": {
        "id": "DIb_W7__9gwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# open raw data scraped from the website\n",
        "with urlopen(\"https://raw.githubusercontent.com/JasaZnidar/totalwaterpolo-web-scraper/523ea70f7c183c38866dc346807f7b59f35b539a/data.json\") as f:\n",
        "    scraped_data = json.load(f)"
      ],
      "metadata": {
        "id": "cvzBR3WG3F7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organize data"
      ],
      "metadata": {
        "id": "oUCmRM4IpJBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "players = {}  # player_id: {total data (not per match)}\n",
        "teams = {}    # team_name: {wins, matches}\n",
        "matches = {}  # match_id: {home_team_name, away_team_name, winner [home, away], home_lineup, away_lineup}\n",
        "\n",
        "for competition in scraped_data['competitions']:\n",
        "  for game in competition['matches']:\n",
        "    matches[game['id']] = {\n",
        "        'home': game['teams']['home'],\n",
        "        'away': game['teams']['away'],\n",
        "        'winner': \"home\" if game['result']['home'] > game['result']['away'] else \"away\" if game['result']['home'] < game['result']['away'] else \"tie\",\n",
        "        'home_lineup': [],\n",
        "        'away_lineup': []\n",
        "    }\n",
        "\n",
        "    #print(json.dumps(game['lineup'], sort_keys=True, indent=4))\n",
        "    for team in ['away', 'home']:\n",
        "      # add new team\n",
        "      if not game['teams'][team] in teams:\n",
        "        teams[game['teams'][team]] = {\n",
        "            'wins': 1 if matches[game['id']]['winner'] == team else 0,\n",
        "            'matches': 1\n",
        "        }\n",
        "      else:\n",
        "        # update team stats\n",
        "        teams[game['teams'][team]]['matches'] += 1\n",
        "        if matches[game['id']]['winner'] == team:\n",
        "          teams[game['teams'][team]]['wins'] += 1\n",
        "\n",
        "      for number in game['lineup'][team]:\n",
        "        try:\n",
        "          id = game['lineup'][team][number]['id']\n",
        "        except KeyError:\n",
        "          # it's a goalgeeker\n",
        "          continue\n",
        "\n",
        "        # add player to match lineup list\n",
        "        matches[game['id']][f\"{team}_lineup\"].append(id)\n",
        "\n",
        "        # check if it's a new player\n",
        "        if not id in players:\n",
        "          players[id] = {\n",
        "              'name': game['lineup'][team][number]['name'],\n",
        "              'goals': 0,\n",
        "              'shots': 0,\n",
        "              'assists': 0,\n",
        "              'blocks': 0,\n",
        "              'played': 1,\n",
        "              'saves': 0,\n",
        "              'exclusions': 0,\n",
        "              'penalties': 0,\n",
        "              'suspensions': 0,\n",
        "              'brutalities': 0,\n",
        "              'sprints': 0,\n",
        "              'sprints_won': 0\n",
        "          }\n",
        "        else:\n",
        "          players[id]['played'] += 1\n",
        "\n",
        "    for play in game['plays']:\n",
        "      # check if a player was marked\n",
        "      if play['player_1'] == 0:\n",
        "        continue\n",
        "\n",
        "      # find teams\n",
        "      team_1 = play['team']\n",
        "      team_2 = \"home\" if team_1 == \"away\" else \"away\"\n",
        "      # check if player is a goalkeeper (IGNORE FOR NOW)\n",
        "      if not 'id' in game['lineup'][team_1][str(play['player_1'])]:\n",
        "        continue\n",
        "\n",
        "      # find players who participated in the play\n",
        "      id_1 = game['lineup'][team_1][str(play['player_1'])]['id']\n",
        "      id_2 = [0, 0] # depending on the play, the second player could be from the same team (first value is the opposing team)\n",
        "      if not play['player_2'] == 0:\n",
        "        id_2[0] = game['lineup'][team_2][str(play['player_2'])]['id']\n",
        "        id_2[1] = game['lineup'][team_1][str(play['player_2'])]['id']\n",
        "\n",
        "      # detect play type\n",
        "      if \"goal scored\" in play['action']:\n",
        "        players[id_1]['shots'] += 1\n",
        "        players[id_1]['goals'] += 1\n",
        "\n",
        "        # was there an assist\n",
        "        if not id_2[1] == 0:\n",
        "          players[id_2[1]]['assists'] += 1\n",
        "      elif \"exclusion\" in play['action']:\n",
        "        players[id_1]['exclusions'] += 1\n",
        "      elif \"penalty foul\" in play['action']:\n",
        "        players[id_1]['penalties'] += 1\n",
        "      elif \"shot missed\" in play['action']:\n",
        "        players[id_1]['shots'] += 1\n",
        "      elif \"shot saved\" in play['action']:\n",
        "        players[id_1]['shots'] += 1\n",
        "      elif \"shot blocked\" in play['action']:\n",
        "        players[id_1]['shots'] += 1\n",
        "        if not id_2[0] == 0:\n",
        "          players[id_2[0]]['blocks'] += 1\n",
        "      elif \"suspention\" in play['action']:\n",
        "        players[id_1]['suspensions'] += 1\n",
        "      elif \"brutality\" in play['action']:\n",
        "        players[id_1]['brutalities'] += 1\n",
        "      elif \"sprint won\" in play['action']:\n",
        "        players[id_1]['sprints_won'] += 1\n",
        "        players[id_1]['sprints'] += 1\n",
        "\n",
        "        # other player sprinting for the ball\n",
        "        if not id_2[0] == 0:\n",
        "          players[id_2[0]]['sprints'] += 1"
      ],
      "metadata": {
        "id": "uNk_ZlepphOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data for learning"
      ],
      "metadata": {
        "id": "LA0qJxTs4BYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some code in this and the Machine learning section was written based on [this article](https://medium.com/@pytorch_geometric/link-prediction-on-heterogeneous-graphs-with-pyg-6d5c29677c70)."
      ],
      "metadata": {
        "id": "DRRpIbMnUG3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = HeteroData()"
      ],
      "metadata": {
        "id": "eTsu0p6ivcY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize data and update it to be per match"
      ],
      "metadata": {
        "id": "AmOTWVvxvYds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = {\n",
        "      'goals': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'shots': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'assists': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'blocks': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'saves': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'exclusions': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'penalties': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'suspensions': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'brutalities': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'sprints': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      },\n",
        "      'matches': {\n",
        "          'min': 1000,\n",
        "          'max': 0\n",
        "      }\n",
        "  }"
      ],
      "metadata": {
        "id": "rcPQGKEdvzgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Player data to per match and get min and max values for normalization"
      ],
      "metadata": {
        "id": "NP9_HA8vw1Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perMatch = {}\n",
        "\n",
        "for player_id in players:\n",
        "  perMatch[player_id] = {\n",
        "      'goals': players[player_id]['goals']/players[player_id]['played'],\n",
        "      'shots': players[player_id]['shots']/players[player_id]['played'],\n",
        "      'assists': players[player_id]['assists']/players[player_id]['played'],\n",
        "      'blocks': players[player_id]['blocks']/players[player_id]['played'],\n",
        "      'saves': players[player_id]['saves']/players[player_id]['played'],\n",
        "      'exclusions': players[player_id]['exclusions']/players[player_id]['played'],\n",
        "      'penalties': players[player_id]['penalties']/players[player_id]['played'],\n",
        "      'suspensions': players[player_id]['suspensions']/players[player_id]['played'],\n",
        "      'brutalities': players[player_id]['brutalities']/players[player_id]['played'],\n",
        "      'sprints': 0.0 if players[player_id]['sprints'] == 0 else players[player_id]['sprints won']/players[player_id]['sprints'],\n",
        "      'matches': players[player_id]['played'],\n",
        "  }\n",
        "\n",
        "  # get min and max for normalization\n",
        "  for key in normalize:\n",
        "    normalize[key]['min'] = min(normalize[key]['min'], perMatch[player_id][key])\n",
        "    normalize[key]['max'] = max(normalize[key]['max'], perMatch[player_id][key])"
      ],
      "metadata": {
        "id": "1BHnYwF_6ekq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize data"
      ],
      "metadata": {
        "id": "bsFn03a0xD2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norm = {}\n",
        "\n",
        "for player_id in perMatch:\n",
        "  norm[player_id] = {}\n",
        "  for key in perMatch[player_id]:\n",
        "    if normalize[key]['min'] == normalize[key]['max']:\n",
        "      norm[player_id][key] = 0.0\n",
        "    else:\n",
        "      norm[player_id][key] = (float(perMatch[player_id][key]) - float(normalize[key]['min']))/(float(normalize[key]['min']) - float(normalize[key]['max']))"
      ],
      "metadata": {
        "id": "X27ACbW3xGiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate team win/loss ratio"
      ],
      "metadata": {
        "id": "HZUiLQUDOsGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WL_ratio = {}\n",
        "\n",
        "for team in teams:\n",
        "  WL_ratio[team] = float(teams[team]['wins'])/float(teams[team]['matches'])"
      ],
      "metadata": {
        "id": "E3p-h6YuOzQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data into HeteroData()"
      ],
      "metadata": {
        "id": "2It5bm4GxPV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Player data"
      ],
      "metadata": {
        "id": "UkwQEt9rxdLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "player_list = list(norm.keys())\n",
        "#player_matrix = torch.tensor([[norm[player_list[p]][list(norm[player_id].keys())[s]] for s in range(11)] for p in range(len(norm))])  # [len(norm), 11]\n",
        "\n",
        "player_matrix = torch.empty(0, 11, dtype=torch.int32)\n",
        "\n",
        "for p in range(len(player_list)):\n",
        "  player_id = player_list[p]\n",
        "  stat_list = list(norm[player_id].keys())\n",
        "\n",
        "  player_matrix = torch.cat((player_matrix, torch.zeros((1, 11), dtype=torch.int32)), 0)\n",
        "  for s in range(len(norm[player_id])):\n",
        "    player_matrix[-1, s] = norm[player_id][stat_list[s]]\n",
        "\n",
        "data['player'].x = player_matrix"
      ],
      "metadata": {
        "id": "FjTMJFA-xbAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Match data"
      ],
      "metadata": {
        "id": "vQmScrKDPQHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teams_matrix = torch.empty(0, 2, dtype=torch.int32)\n",
        "result_matrix = torch.empty(2, 0, dtype=torch.int64)\n",
        "result_attr = torch.empty(1, 0, dtype=torch.float32)\n",
        "\"\"\"home_matrix = torch.empty(2, 0)\n",
        "away_matrix = torch.empty(2, 0)\n",
        "tie_matrix = torch.empty(2, 0)\"\"\"\n",
        "played_matrix = torch.empty(2, 0, dtype=torch.int64)\n",
        "match_list = list(matches.keys())\n",
        "\n",
        "for match in matches:\n",
        "  # home team\n",
        "  i_home = teams_matrix.size(dim=0)\n",
        "  teams_matrix = torch.cat((teams_matrix, torch.zeros((1, 2), dtype=torch.int32)))\n",
        "  teams_matrix[-1, 0] = WL_ratio[matches[match]['home']]\n",
        "  teams_matrix[-1, 1] = 0.0\n",
        "\n",
        "  # home lineup\n",
        "  for player in matches[match]['home_lineup']:\n",
        "    played_matrix = torch.cat((played_matrix, torch.zeros((2, 1), dtype=torch.int32)), dim=1)\n",
        "    played_matrix[0, -1] = player_list.index(player)\n",
        "    played_matrix[1, -1] = i_home\n",
        "    pass\n",
        "\n",
        "  # away team\n",
        "  i_away = teams_matrix.size(dim=0)\n",
        "  teams_matrix = torch.cat((teams_matrix, torch.zeros((1, 2), dtype=torch.int32)))\n",
        "  teams_matrix[-1, 0] = WL_ratio[matches[match]['away']]\n",
        "  teams_matrix[-1, 1] = 1.0\n",
        "\n",
        "  # away lineup\n",
        "  for player in matches[match]['away_lineup']:\n",
        "    played_matrix = torch.cat((played_matrix, torch.zeros((2, 1), dtype=torch.int32)), dim=1)\n",
        "    played_matrix[0, -1] = player_list.index(player)\n",
        "    played_matrix[1, -1] = i_away\n",
        "    pass\n",
        "\n",
        "  # result relation\n",
        "  result_matrix = torch.cat((result_matrix, torch.zeros((2, 1), dtype=torch.int32)), dim=1)\n",
        "  result_matrix[0, -1] = i_home\n",
        "  result_matrix[1, -1] = i_away\n",
        "  if matches[match]['winner'] == \"home\":\n",
        "    \"\"\"home_matrix = torch.cat((home_matrix, torch.zeros((2, 1))), dim=1)\n",
        "    home_matrix[0, -1] = i_home\n",
        "    home_matrix[1, -1] = i_away\"\"\"\n",
        "    result_attr = torch.cat((result_attr, torch.zeros((1, 1), dtype=torch.float32)), dim=1)\n",
        "    result_attr[0, -1] = 0.0\n",
        "  elif matches[match]['winner'] == \"away\":\n",
        "    \"\"\"away_matrix = torch.cat((away_matrix, torch.zeros((2, 1))), dim=1)\n",
        "    away_matrix[0, -1] = i_away\n",
        "    away_matrix[1, -1] = i_home\"\"\"\n",
        "    result_attr = torch.cat((result_attr, torch.zeros((1, 1), dtype=torch.float32)), dim=1)\n",
        "    result_attr[0, -1] = 1.0\n",
        "  else:\n",
        "    \"\"\"tie_matrix = torch.cat((tie_matrix, torch.zeros((2, 1))), dim=1)\n",
        "    tie_matrix[0, -1] = i_home\n",
        "    tie_matrix[1, -1] = i_away\"\"\"\n",
        "    result_attr = torch.cat((result_attr, torch.zeros((1, 1), dtype=torch.float32)), dim=1)\n",
        "    result_attr[0, -1] = 0.5\n",
        "\n",
        "data['team'].x = teams_matrix\n",
        "\"\"\"data['team', 'home', 'team'].edge_index = home_matrix\n",
        "data['team', 'away', 'team'].edge_index = away_matrix\n",
        "data['team', 'tie', 'team'].edge_index = tie_matrix\"\"\"\n",
        "data['team', 'result', 'team'].edge_index = result_matrix\n",
        "data['team', 'result', 'team'].edge_attr = result_attr\n",
        "data['player', 'play', 'team'].edge_index = played_matrix\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "ng_MuqZ5PVJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27bf1f2-a35b-4ece-d78a-34ddaa05db64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroData(\n",
            "  player={ x=[2551, 11] },\n",
            "  team={ x=[1236, 2] },\n",
            "  (team, result, team)={\n",
            "    edge_index=[2, 618],\n",
            "    edge_attr=[1, 618],\n",
            "  },\n",
            "  (player, play, team)={ edge_index=[2, 13827] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final adjustments"
      ],
      "metadata": {
        "id": "7G9Fg3BF7FIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make undirected\n",
        "data_undirected = T.ToUndirected()(data)\n",
        "\n",
        "\"\"\"neighbors = {\n",
        "    'match': 1,\n",
        "    'team': 1,\n",
        "    'player': 11,\n",
        "    'goalkeeper': 2,\n",
        "    'played': 100\n",
        "}\"\"\"\n",
        "neighbors = {\n",
        "    (\"team\", \"result\", \"team\"): [14, 1, 20],\n",
        "}\n",
        "loader = LinkNeighborLoader(\n",
        "    data,\n",
        "    num_neighbors=neighbors,\n",
        "    batch_size=128,\n",
        "    edge_label_index=((\"team\", \"result\", \"team\"), data['team', 'result', 'team'].edge_index)\n",
        ")\n",
        "\n",
        "#print(next(iter(loader)))\n",
        "\n",
        "# split data into training, validation and testing\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.3,\n",
        "    num_test=0.0,\n",
        "    is_undirected=True,\n",
        "    disjoint_train_ratio=0.3,\n",
        "    neg_sampling_ratio=2.0,\n",
        "    add_negative_train_samples=False,\n",
        "    edge_types=(\"team\", \"result\", \"team\")\n",
        ")\n",
        "train_data, val_data, test_data = transform(data_undirected)\n",
        "\n",
        "# update data to include neighbors\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,\n",
        "    num_neighbors=[11],\n",
        "    neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"team\", \"result\", \"team\"), train_data[\"team\", \"result\", \"team\"].edge_label_index),\n",
        "    edge_label=train_data[\"team\", \"result\", \"team\"].edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True\n",
        ")\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,\n",
        "    num_neighbors=[11],\n",
        "    edge_label_index=((\"team\", \"result\", \"team\"), val_data[\"team\", \"result\", \"team\"].edge_label_index),\n",
        "    edge_label=val_data[\"team\", \"result\", \"team\"].edge_label,\n",
        "    batch_size=3*128,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(next(iter(loader)))"
      ],
      "metadata": {
        "id": "zKNSvqQS7Axm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "46171cc1-d9b9-4715-9fce-7b74f1cb6758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Missing number of neighbors for edge type '('player', 'play', 'team')'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5dfa2f3aea74>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/link_loader.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEdgeSamplerInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         out = self.link_sampler.sample_from_edges(\n\u001b[0m\u001b[1;32m    212\u001b[0m             input_data, neg_sampling=self.neg_sampling)\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36msample_from_edges\u001b[0;34m(self, inputs, neg_sampling)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mneg_sampling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNegativeSampling\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 334\u001b[0;31m         out = edge_sample(inputs, self._sample, self.num_nodes, self.disjoint,\n\u001b[0m\u001b[1;32m    335\u001b[0m                           self.node_time, neg_sampling)\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSubgraphType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36medge_sample\u001b[0;34m(inputs, sample_fn, num_nodes, disjoint, node_time, neg_sampling)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 }\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_time_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;31m# Enhance `out` by label information ##################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                     \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_neighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mapped_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/base.py\u001b[0m in \u001b[0;36mget_mapped_values\u001b[0;34m(self, edge_types)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_mapped_values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_mapped_values'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/base.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, edge_types, mapped)\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                         raise ValueError(f\"Missing number of neighbors for \"\n\u001b[0m\u001b[1;32m    437\u001b[0m                                          f\"edge type '{edge_type}'\")\n\u001b[1;32m    438\u001b[0m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge_type_str\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmapped\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0medge_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Missing number of neighbors for edge type '('player', 'play', 'team')'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning"
      ],
      "metadata": {
        "id": "qd1yf4Tn0sKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GNN module"
      ],
      "metadata": {
        "id": "t6mEs7cHcx51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.GCNConv(hidden_channels, hidden_channels)\n",
        "    self.conv2 = nn.GCNConv(hidden_channels, hidden_channels)\n",
        "    self.linear1 = torch.nn.Linear(hidden_channels,1)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = torch.nn.functional.relu(self.conv1(x, edge_index))\n",
        "    x = self.conv2(x, edge_index)\n",
        "    x = self.linear1(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "XewxSir-1aRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN"
      ],
      "metadata": {
        "id": "01sRc2TZEGyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels, conv_layers=2):\n",
        "    super().__init__()\n",
        "    self.conv = []\n",
        "    for _ in range(conv_layers):\n",
        "      self.conv.append(nn.RGCNConv(hidden_channels, hidden_channels))\n",
        "    self.linear = torch.nn.Linear(hidden_channels, 1)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = self.conv[0](x, edge_index)\n",
        "    for i in range(1, len(self.conv)):\n",
        "      x = torch.nn.functional.relu(x)\n",
        "      x = self.conv[i](x, edge_index)\n",
        "\n",
        "    x = self.linear(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "KWFRaM9eEKF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifer\n",
        "Used to create edge-level prediction"
      ],
      "metadata": {
        "id": "4vzOpngAc19s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "  def forward(self, x_home, x_away, edge_label_index):\n",
        "    edge_feat_home = x_home[edge_label_index[0]]\n",
        "    edge_feat_away = x_away[edge_label_index[1]]\n",
        "    print((edge_feat_home * edge_feat_away))\n",
        "\n",
        "    return (edge_feat_home * edge_feat_away).sum(dim=1)"
      ],
      "metadata": {
        "id": "GE7z8xFcdBXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "mvSWvcGMd_sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels):\n",
        "    super().__init__()\n",
        "\n",
        "    self.team_emb = torch.nn.Embedding(data['team'].num_nodes, hidden_channels)\n",
        "    self.player_emb = torch.nn.Embedding(data['player'].num_nodes, hidden_channels)\n",
        "\n",
        "    self.gnn = GNN(hidden_channels)\n",
        "\n",
        "    self.classifier = Classifier()\n",
        "  def forward(self, data):\n",
        "    \"\"\"x_dict = {\n",
        "      'team': self.team_emb(data['team'].n_id),\n",
        "      'player': self.player_emb(data['player'].n_id)\n",
        "    }\"\"\"\n",
        "\n",
        "    x = self.gnn(data['team'].x, data.edge_index_dict)\n",
        "    \"\"\"pred = self.classifier(\n",
        "        x_dict['team'],\n",
        "        x_dict['team'],\n",
        "        data['team', 'result', 'team'].edge_label_index\n",
        "    )\"\"\"\n",
        "\n",
        "    pred = self.linear1(x)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "0xNn7zVTeA9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "k1nbDFItfvHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(64)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(16):\n",
        "  total_loss = total_examples = 0\n",
        "  for sampled_data in tqdm.tqdm(train_loader):\n",
        "    print(sampled_data)\n",
        "    optimizer.zero_grad()\n",
        "    sampled_data.to(device)\n",
        "    pred = model(sampled_data)\n",
        "    ground_truth = sampled_data['team', 'result', 'team'].edge_label\n",
        "    loss = torch.nn.functional.binary_cross_entropy_with_logits(pred, ground_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += float(loss) * pred.numel()\n",
        "    total_examples += pred.numel()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "m30eApwATQwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate"
      ],
      "metadata": {
        "id": "iZlT0tODsL22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "ground_truths = []\n",
        "sampled_data = next(iter(val_loader))\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        sampled_data.to(device)\n",
        "        preds.append(model(sampled_data))\n",
        "        ground_truths.append(sampled_data['team', 'result', 'team'].edge_label)\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "auc = roc_auc_score(ground_truth, pred)\n",
        "fpr, tpr, _ = roc_curve(ground_truth, pred)\n",
        "\n",
        "print()\n",
        "plt.plot([0, 1], [0, 1], color=\"red\", lw=2, linestyle=\"--\")\n",
        "plt.plot(fpr,tpr, color=\"navy\")\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "print(f\"Validation AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "p7-fkM0MwYXf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}